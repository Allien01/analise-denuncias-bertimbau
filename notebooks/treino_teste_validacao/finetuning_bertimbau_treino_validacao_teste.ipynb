{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kkt3yw00IoE"
   },
   "source": [
    "@inproceedings{souza2020bertimbau,\n",
    "  author    = {F{\\'a}bio Souza and\n",
    "               Rodrigo Nogueira and\n",
    "               Roberto Lotufo},\n",
    "  title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n",
    "  booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n",
    "  year      = {2020}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIfaYOAKr0R6"
   },
   "source": [
    "# **Conectando ao Google Drive**\n",
    "\n",
    "\n",
    "Para acessar e carregar os dados necessários para o projeto, montamos o Google Drive. Isso permite que o notebook leia arquivos diretamente de uma pasta em sua conta, facilitando o gerenciamento e a persistência dos dados entre diferentes sessões. O comando a seguir solicita permissão para conectar o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey0-HM5ocnvu",
    "outputId": "a9b9328b-3534-4483-a329-00d111a3dab4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcTbLWwTr74s",
    "outputId": "0b0d708d-b76d-4d79-9df0-fab2a37ade21"
   },
   "outputs": [],
   "source": [
    "!pip install transformers evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feHRGfqdONsa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "start_total_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkRUcLU1PHke"
   },
   "source": [
    "# **1. Carregar Dataset Processado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ti1knC9saC_"
   },
   "source": [
    "Nesta etapa, o conjunto de dados é preparado para o treinamento do modelo. O ***arquivo denuncias_balanceadas.xlsx*** é dividido em três partes: treino (70%), validação (15%) e teste (15%), garantindo que cada conjunto tenha uma distribuição similar das classes ***invasao_domicilio*** e ***violencia_fisica***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O3x60E3PHtT",
    "outputId": "26b891c3-8f45-4c4e-c7bd-3fcf00226880"
   },
   "outputs": [],
   "source": [
    "# Carregar dataset já processado\n",
    "file_path = '/content/drive/MyDrive/2025/tcc-final/denuncias_balanceadas.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Dividir em treino (70%), validação (15%) e teste (15%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['classe'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['classe'], random_state=42)\n",
    "\n",
    "print(f\"Treino: {len(train_df)}, Validação: {len(val_df)}, Teste: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3WAEgOPYHa"
   },
   "source": [
    "# **2. Tokenização com BERTimbau**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcpyLSPJstl_"
   },
   "source": [
    "Para que o modelo BERTimbau entenda nossos textos, é preciso convertê-los em um formato numérico. Este processo, chamado de tokenização, utiliza o ***AutoTokenizer*** do modelo BERTimbau, que é um modelo de linguagem pré-treinado especificamente para o português do Brasil. O ***tokenizer*** quebra os textos em ***tokens*** (palavras ou partes de palavras) e os mapeia para números que o modelo pode processar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324,
     "referenced_widgets": [
      "cb707cdadc30457db3d7339b1b4b0320",
      "5b99bfce46134dd9b9cdf0541f48faa0",
      "04906647f10b4417b932c73412f2d4ae",
      "16d05d7abc8046e08127884b28c663bd",
      "95d560634d6844899985b59f71a1aa7c",
      "00b70359e7e84551a09c3993f3ed3201",
      "7a538bae48144acaaf641f4cd2083136",
      "460ce78155a34c8297e55406cdb12c6b",
      "3aa3caa17d1647d79cd8ee0b12404686",
      "edee44e27b8744c797919612235c872e",
      "5ef4a3a29ef84caeb7af776da70d15be",
      "573749a597e04ba18fd36a39aa9f8690",
      "ba3612265dd94de198b48e2ddc5a0bb7",
      "8e5131e63224410aacc4b8e8399a7996",
      "51bad4bd42644fa3bd58919ee5679ae8",
      "3c273adde4994130a4e2bc2957ecd05d",
      "3d780a4b669744ee80431084ede85a15",
      "e54c68649c514246ad07602da725f7de",
      "f58b7741f43c4221a7ef52360fceae87",
      "9fa3f68de4d149879e4051e2c2f59518",
      "2a7995ca76c9451e87a3b64a0508a0e6",
      "af5f366ff14d4cd2975f398babf71efa",
      "51c963e0d10e4d729437ea1c3683088f",
      "b180bed95dd04324aba29070af8b8a1c",
      "6999ca8d599544429509d5bac4c4fbd6",
      "9892ea592c364067ad27d5f0369e7d61",
      "344560c4e660457cb70c351eea6f89ed",
      "45720156b1254f88b9ea97c01065df25",
      "4a144d4a086d40fc940a06136bfd6115",
      "e7a15e16aea343ffb713b80448774451",
      "1150dec4f8a442319f623fee933fa10c",
      "96d4097733cd4543a73bd0efd2105fcd",
      "77e91a5db4e94d00b91ee68edad32d07",
      "657c2257a3dd4a979fd73679ade32ba2",
      "cfdca968dbfb4f9899fbdae1310c1875",
      "eda64d5a721540c2936f570f026881cb",
      "abffef56011b4323a6f282fa4082353b",
      "3c47e5f5d44a426ea76b2bf8d3a2cbe5",
      "8610e2b5a4934c07951eaa5a24e3595e",
      "14e52dcac6c34d8f8baf73f8b2d4ede3",
      "02b738b0f528439da60cecec0294f97d",
      "3f67b7d863664ea2b4e2b553f88aa3bf",
      "71a31eedb4a947d5a7b12b66e7f454c3",
      "2bea632ff8024062acd77151b4f0b53b",
      "87712f483e79436493c6fefea04cfb5d",
      "6be07e4a213c4749a7af7c561ab0cf7c",
      "8ed027a3733248a88e9e806e9ea683cb",
      "88cbad2d80cc44c69d30b0e5ec0d2d5b",
      "d461fe3abda640db8ea270f9f675fde5",
      "71ace282e7914d90a78e4529e4112436",
      "0e572cc0b1824ca6937cc5bc037a7215",
      "2d81cf96cba149bb87624288f8944f5a",
      "956d368646c7451198f8d8a2182bc39e",
      "1acbc00e6b5a414b819430e1ee54cdf3",
      "0a99b6988c374d1692004b322ec89444"
     ]
    },
    "id": "sql7RSXMPd1g",
    "outputId": "0e5219b5-8a25-46f8-8e1c-c20652effe64"
   },
   "outputs": [],
   "source": [
    "model_path = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Função de tokenização\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"texto\"], truncation=True,max_length=512, padding='longest',return_tensors='pt')\n",
    "\n",
    "# Tokenizar os DataFrames diretamente (sem usar datasets.Dataset)\n",
    "train_encodings = tokenize_function(train_df.to_dict('list'))\n",
    "val_encodings = tokenize_function(val_df.to_dict('list'))\n",
    "test_encodings = tokenize_function(test_df.to_dict('list'))\n",
    "print(train_encodings[0])\n",
    "print(val_encodings[0])\n",
    "print(test_encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0mzN3JPP-s4"
   },
   "source": [
    "# **3. Configuração do Modelo: Adaptando o BERTimbau para a nossa tarefa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKh_g5Rfs27y"
   },
   "source": [
    "Aqui, carregamos o modelo BERTimbau pré-treinado e o adaptamos para a nossa tarefa de classificação de texto. A parte mais importante desta etapa é a configuração da camada final (chamada de ***classifier***), que será treinada para prever uma de nossas duas classes. Além disso, congelamos as camadas de base do BERT, o que significa que apenas a nova camada do classificador será ajustada, otimizando o treinamento para um conjunto de dados menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114,
     "referenced_widgets": [
      "6136bfa64b9540fe85777b477fc507bd",
      "5ba8ecab98a94cbf8514a42332eb2b27",
      "00fd42b0d8b84c2495d2f3c7cea62967",
      "91c3dc9321f84edfa33b8765834f7f24",
      "839b580ffbd34d74b94f2cdad5f66ddf",
      "fe2cdde9f4ef4ee69b7f63f790b49a25",
      "e810f63f6f9a4df69b5d911b5dddecfc",
      "61fdc8ee2da2437398f201f78cbb6f7d",
      "3b1a9dac97e74e6eaa3c2c3adc4af6f1",
      "5229573cd29a4a04a6ea20e27fa5cf3c",
      "ce9c17b3f9be473e844b4c7f59042b8c",
      "1cbf6ab549f64322b73e44b18d921947",
      "acb2af4eb098495599f911ab3196d86d",
      "cc08a07355544e4fa14b677210956395",
      "39de2cff1b654036baa4e0890a49bec1",
      "0baea245ad7343a79c8200c441ecda18",
      "2535d7598414408eb4e83b39e6651c13",
      "04a3335acf064e87931e29a89554985a",
      "95d6867b283d4300ae7d5daf87d9484f",
      "c6821dedeebf4207b66465a96b4932d2",
      "1003315c97fb4ca49faf203e5484bd82",
      "fe65b8cf433d410892ba2e93b131e089"
     ]
    },
    "id": "tkQIL_4sYTMq",
    "outputId": "18e4220d-d6cd-429a-e3fa-0eebb30856f0"
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"invasao_domicilio\", 1: \"violencia_fisica\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Congelar camadas do BERT (exceto pooler e classificador)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name and 'pooler' not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S-nz2HQZ0CA"
   },
   "source": [
    "# **4. Avaliação do Modelo: Definindo as métricas de sucesso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38r3L7Pbs9xI"
   },
   "source": [
    "Para saber se o nosso modelo está aprendendo bem, precisamos de métricas de avaliação. Além da ***acurácia*** (a porcentagem de acertos), calculamos outras métricas importantes, como a ***AUC-ROC***, que mede a capacidade do modelo de distinguir entre as classes, e a ***Precisão, Recall e F1-Score***, que nos dão uma visão mais detalhada sobre o desempenho do modelo em cada classe (invasão de domicílio e violência física)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "a1170ed0836c422e87c7123f2907d303",
      "4ffb2149d269422caa0a8e1be575f928",
      "3a74d2edc25b4f94bdda5b62c2889e43",
      "5780600c73e94472a7e5f3b86560c4d4",
      "ef2acc6a813c4eb5a6f0a902bc1ddacd",
      "07e5061afcfe40c7912c7f29a3a69406",
      "5a80034c9cd548a08c35ec6adb17fcda",
      "2a44c37e01e548fe8c8356e49e0f71a0",
      "9d3e331b1a1a41eeb271c80361786aad",
      "fdd614ee28714fbdb0d376d8bae9586b",
      "ed0c0552a9c84b3c99446346280ebce6",
      "f30e4230185c448e9669c431c15d24b9",
      "87194401aa394cad807ea1772e6f10aa",
      "4df4d5c5c7b648dfa4bf3649b6e76586",
      "79753cf78ebf4aa793c15d3401c38e4c",
      "74d0a0b1c3584a8eab7cb635836e07a9",
      "c097ace3b4a8489b979fcbf2107fd653",
      "00b883f979954e3c9d085f932c7aeffc",
      "03bafce9f8344e03966ee20ad009e310",
      "19ccedeba05c40a2bc3490ee6a5acd67",
      "45719dc269df4c7d8cf03ab0370fddc1",
      "c6eb6c455cdc480d90c8aa88f5e3a409",
      "f551de03e4bb4fb69755ce5cb597c7b7",
      "7496004d5dc5458cbefb71412e3fcd05",
      "b4561c758668464ebc402d4182647e13",
      "7bb26b6305f242488d5e85cf953ca8cd",
      "5978b18d9d054751931955b2ec7a4151",
      "b200f4555c4f4e28897e80b0dffdeb57",
      "ba242613e3344ae59f7b9f9e417fedbc",
      "d438695493cb4d2da82a28d6dc41993c",
      "557a08203a814cd0858416040b8d8b33",
      "a7081a5f583e4aa9aa935788fc6215b5",
      "df6eed8e13d24e4ba50f58b146144809",
      "4121165160cb430ab6fc9537c8af13d7",
      "84ec6a64b2544fdcba3f85d711040006",
      "958a620a3fb44606952b6323e9144f62",
      "52db66681f364927a17ecd9e17f0e249",
      "086017ab9e364d45a95a546afb531c01",
      "90096a57ee63435b8a7b25136a7ed443",
      "d1d69232be954dca81bbe95956fe31f4",
      "e60e35f2a5614ec3aede09ca5d3b16e1",
      "99299362c679456e861e793bff909432",
      "22d4d2e33f14482693ace954105d36be",
      "b9b531f5a39b432cad7065e2b5719e8d",
      "16ed69192c5f4f5d88177f5836ff96e0",
      "f6e49bcec2844bb292c17666ff42b357",
      "8b11a8a8443b4b7d845a14ccda9d4ae4",
      "449c20e26f70421e8e602ee3b417b332",
      "21455cc0c664467c9f26395675bbbff4",
      "b1966d08036e4a7e9a8aaf8230aec20b",
      "707f1d9afd414976bf3c12036feaa9c7",
      "7c93f77c6899402f88dc8f46d814b567",
      "1bfaadf8af1e45f6b5e97a4f61bf41e8",
      "66b99ef36e7445e5803acc1f936b6a59",
      "b79c8356353d46e5b77a0e056545545d"
     ]
    },
    "id": "F-gctrIbZ1Pv",
    "outputId": "57b788c2-ab63-43f1-d2b9-a4626336bb24"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    try:\n",
    "        predictions, labels = eval_pred\n",
    "        probabilities = np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)) / np.sum(np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)), axis=-1, keepdims=True)\n",
    "        positive_class_probs = probabilities[:, 1]\n",
    "\n",
    "        preds = np.argmax(predictions, axis=1)\n",
    "        acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "        auc = auc_score.compute(prediction_scores=positive_class_probs, references=labels)[\"roc_auc\"]\n",
    "\n",
    "        f1_results = f1_metric.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        precision_results = precision.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        recall_results = recall.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": round(acc, 4),\n",
    "            \"auc\": round(auc, 4),\n",
    "            \"f1_invasao\": round(f1_results[\"f1\"][0], 4),\n",
    "            \"f1_violencia\": round(f1_results[\"f1\"][1], 4),\n",
    "            \"precision_invasao\": round(precision_results[\"precision\"][0], 4),\n",
    "            \"precision_violencia\": round(precision_results[\"precision\"][1], 4),\n",
    "            \"recall_invasao\": round(recall_results[\"recall\"][0], 4),\n",
    "            \"recall_violencia\": round(recall_results[\"recall\"][1], 4),\n",
    "            \"precision_macro\": round(np.mean(precision_results[\"precision\"]), 4),\n",
    "            \"recall_macro\": round(np.mean(recall_results[\"recall\"]), 4),\n",
    "            \"f1_macro\": round(np.mean(f1_results[\"f1\"]), 4)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no cálculo de métricas: {str(e)}\")\n",
    "        return {\"accuracy\": 0.0, \"auc\": 0.0, \"f1_invasao\": 0.0, \"f1_violencia\": 0.0,\n",
    "                \"precision_invasao\": 0.0, \"precision_violencia\": 0.0,\n",
    "                \"recall_invasao\": 0.0, \"recall_violencia\": 0.0,\n",
    "                \"precision_macro\": 0.0, \"recall_macro\": 0.0, \"f1_macro\": 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwkxUjbiuniC"
   },
   "source": [
    "# **5. Treinamento: A mágica do Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6u5QzNauoN1"
   },
   "source": [
    "Nesta seção, iniciamos o treinamento do modelo usando a biblioteca ***Hugging Face Trainer***. O treinamento será executado por 30 épocas. O ***EarlyStoppingCallback*** é ativado para interromper o treinamento caso o desempenho do modelo no conjunto de validação pare de melhorar por três épocas consecutivas, evitando o overfitting. Você pode acompanhar a evolução da perda (loss) e da acurácia durante o processo no gráfico abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "id": "Lu5KpVfWaGA3",
    "outputId": "bc21b905-1899-4a3f-f6fd-54359bffd0c6"
   },
   "outputs": [],
   "source": [
    "\"\"\"train_losses_plot, val_losses_plot, test_losses_plot = [], [], []\n",
    "train_accuracies_plot, val_accuracies_plot, test_accuracies_plot = [], [], []\n",
    "\n",
    "# Configuração dos argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertimbau-denuncias\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,  # ✅ Ajustado para 1e-5 (como no K-Fold)\n",
    "    num_train_epochs=30,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",  # ✅ Mudado de logging_steps para epoch\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Data Collator para padding dinâmico\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Custom Dataset (para trabalhar com DataFrames)\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        # Converte para tensor e garante que encodings.items() tem os valores corretos\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        # Converte labels para tensor, lidando com pd.Series ou listas/arrays\n",
    "        self.labels = torch.tensor(labels.values if isinstance(labels, pd.Series) else labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Criar datasets\n",
    "# Assegure que train_df, val_df, test_df e label2id estejam definidos.\n",
    "# .tolist() é importante para garantir que labels sejam um tipo Python nativo antes de converter para tensor no CustomDataset.\n",
    "train_dataset = CustomDataset(train_encodings, train_df['classe'].map(label2id).tolist())\n",
    "val_dataset = CustomDataset(val_encodings, val_df['classe'].map(label2id).tolist())\n",
    "test_dataset = CustomDataset(test_encodings, test_df['classe'].map(label2id).tolist())\n",
    "\n",
    "# Instanciar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset, # O trainer usará este para avaliação automática por época\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold = 1e-3)],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\n🚀 Iniciando treinamento...\")\n",
    "\n",
    "    # O trainer.train() irá executar o treinamento e as avaliações de validação\n",
    "    # por época, além de carregar o melhor modelo no final.\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    # --- Extrair métricas dos logs para os gráficos ---\n",
    "    # Os logs contêm as métricas de treino e validação por época\n",
    "    logs = trainer.state.log_history\n",
    "\n",
    "    # Iterar sobre os logs para preencher as listas de plotagem\n",
    "    for log_entry in logs:\n",
    "        # Perdas de Treino: o 'loss' é logado para o treinamento\n",
    "        if 'loss' in log_entry and 'eval_loss' not in log_entry:\n",
    "            train_losses_plot.append(log_entry['loss'])\n",
    "\n",
    "        # Métricas de Validação: logadas com prefixo 'eval_'\n",
    "        if 'eval_loss' in log_entry and 'eval_accuracy' in log_entry:\n",
    "            val_losses_plot.\"\"append(log_entry['eval_loss'])\n",
    "            val_accuracies_plot.append(log_entry['eval_accuracy'])\n",
    "\n",
    "    # --- Avaliação final do melhor modelo no conjunto de teste ---\n",
    "    # Este é o ponto mais importante para as métricas finais do seu modelo.\n",
    "    print(\"\\n🧪 Avaliação final do melhor modelo no conjunto de teste...\")\n",
    "    final_test_metrics = trainer.evaluate(test_dataset)\n",
    "\n",
    "    # --- 📊 Gráficos de comparação por época ---\n",
    "\n",
    "    # O número de épocas para plotagem será o número de avaliações de validação registradas\n",
    "    epochs_completed = len(val_accuracies_plot)\n",
    "    epochs_to_plot = list(range(1, epochs_completed + 1))\n",
    "\n",
    "    train_losses_for_plot = train_losses_plot[-epochs_completed:] if len(train_losses_plot) >= epochs_completed else train_losses_plot\n",
    "\n",
    "    if not epochs_to_plot:\n",
    "        print(\"\\nNão há dados suficientes para gerar os gráficos. Verifique o processo de treinamento e coleta de métricas.\")\n",
    "    else:\n",
    "        # Loss por época (Treino, Validação)\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(epochs_to_plot, train_losses_for_plot, label=\"Treino\", marker='o')\n",
    "        plt.plot(epochs_to_plot, val_losses_plot, label=\"Validação\", marker='o')\n",
    "        # Plotar o resultado final do teste como um ponto ou linha horizontal.\n",
    "        plt.xlabel(\"Época\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Loss por Época (Treino, Validação)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training or evaluation: {e}\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FZYLPL15MDKG",
    "outputId": "f875af95-ec7a-4be2-b83a-c2d4034c978b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "# Listas para armazenar métricas para plotagem\n",
    "train_losses_plot, val_losses_plot = [], []\n",
    "train_accuracies_plot, val_accuracies_plot = [], []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuração dos argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertimbau-denuncias\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=30,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Data Collator para padding dinâmico\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Custom Dataset (para trabalhar com DataFrames)\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels.values if isinstance(labels, pd.Series) else labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Criar datasets\n",
    "print(\"\\n📊 Preparando datasets...\")\n",
    "train_dataset = CustomDataset(train_encodings, train_df['classe'].map(label2id).tolist())\n",
    "val_dataset = CustomDataset(val_encodings, val_df['classe'].map(label2id).tolist())\n",
    "test_dataset = CustomDataset(test_encodings, test_df['classe'].map(label2id).tolist())\n",
    "\n",
    "print(f\"✅ Datasets criados:\")\n",
    "print(f\"   • Treino: {len(train_dataset)} amostras\")\n",
    "print(f\"   • Validação: {len(val_dataset)} amostras\")\n",
    "print(f\"   • Teste: {len(test_dataset)} amostras\")\n",
    "\n",
    "# Instanciar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=1e-3)],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 INICIANDO TREINAMENTO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Treinar o modelo\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    # --- EXTRAIR MÉTRICAS DOS LOGS PARA OS GRÁFICOS ---\n",
    "    print(\"\\n📊 Coletando métricas de treinamento...\")\n",
    "    logs = trainer.state.log_history\n",
    "\n",
    "    # Limpar listas (caso esteja rodando múltiplas vezes)\n",
    "    train_losses_plot = []\n",
    "    val_losses_plot = []\n",
    "    train_accuracies_plot = []\n",
    "    val_accuracies_plot = []\n",
    "\n",
    "    # Iterar sobre os logs para preencher as listas\n",
    "    for log_entry in logs:\n",
    "        # Perdas de Treino: o 'loss' é logado para o treinamento\n",
    "        if 'loss' in log_entry and 'eval_loss' not in log_entry:\n",
    "            train_losses_plot.append(log_entry['loss'])\n",
    "\n",
    "        # Métricas de Validação: logadas com prefixo 'eval_'\n",
    "        if 'eval_loss' in log_entry and 'eval_accuracy' in log_entry:\n",
    "            val_losses_plot.append(log_entry['eval_loss'])\n",
    "            val_accuracies_plot.append(log_entry['eval_accuracy'])\n",
    "\n",
    "    # Diagnóstico\n",
    "    print(f\"\\n📊 Métricas coletadas:\")\n",
    "    print(f\"   • Train losses: {len(train_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation losses: {len(val_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation accuracies: {len(val_accuracies_plot)} épocas\")\n",
    "\n",
    "    # ⚠️ GARANTIR MESMO TAMANHO\n",
    "    min_length = min(len(train_losses_plot), len(val_losses_plot))\n",
    "    if len(train_losses_plot) != len(val_losses_plot):\n",
    "        print(f\"   ⚠️ AVISO: Tamanhos diferentes! Ajustando para {min_length} épocas\")\n",
    "        train_losses_plot = train_losses_plot[:min_length]\n",
    "        val_losses_plot = val_losses_plot[:min_length]\n",
    "        val_accuracies_plot = val_accuracies_plot[:min_length]\n",
    "\n",
    "    # Métricas finais de treino\n",
    "    print(f\"\\n📊 Métricas finais de treino:\")\n",
    "    print(f\"   Loss: {train_results.metrics.get('train_loss', 'N/A'):.4f}\")\n",
    "    print(f\"   Tempo total: {train_results.metrics.get('train_runtime', 'N/A'):.2f}s\")\n",
    "\n",
    "    # ✅ CALCULAR TRAIN ACCURACY\n",
    "    print(f\"\\n📊 Calculando Train Accuracy...\")\n",
    "    train_predictions_output = trainer.predict(train_dataset)\n",
    "    train_predictions = np.argmax(train_predictions_output.predictions, axis=1)\n",
    "    train_labels_array = train_predictions_output.label_ids\n",
    "    train_accuracy_final = (train_predictions == train_labels_array).mean()\n",
    "    print(f\"   Train Accuracy: {train_accuracy_final:.4f}\")\n",
    "\n",
    "    # Avaliação no conjunto de VALIDAÇÃO\n",
    "    print(f\"\\n🔍 Avaliação no conjunto de VALIDAÇÃO...\")\n",
    "    val_metrics = trainer.evaluate(val_dataset)\n",
    "    print(f\"   Resultados de validação:\")\n",
    "    for key, value in val_metrics.items():\n",
    "        print(f\"      • {key}: {value:.4f}\")\n",
    "\n",
    "    # ✅ CALCULAR GAP\n",
    "    final_train_loss = train_results.metrics.get('train_loss', 0)\n",
    "    final_val_loss = val_metrics.get('eval_loss', 0)\n",
    "    gap = final_val_loss - final_train_loss\n",
    "    gap_pct = (gap / final_train_loss) * 100 if final_train_loss > 0 else 0\n",
    "\n",
    "    print(f\"\\n📏 Análise de GAP:\")\n",
    "    print(f\"   Train Loss: {final_train_loss:.6f}\")\n",
    "    print(f\"   Val Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"   GAP: {gap:.6f} ({gap_pct:.2f}%)\")\n",
    "    if gap < 0.10:\n",
    "        print(f\"   Status: ✅ Bom\")\n",
    "    elif gap < 0.15:\n",
    "        print(f\"   Status: ⚠️ Atenção\")\n",
    "    else:\n",
    "        print(f\"   Status: 🚨 Overfitting\")\n",
    "\n",
    "    # --- 📊 GRÁFICOS DE COMPARAÇÃO POR ÉPOCA ---\n",
    "    print(f\"\\n📊 Gerando gráficos...\")\n",
    "\n",
    "    epochs_completed = min_length\n",
    "    epochs_to_plot = list(range(1, epochs_completed + 1))\n",
    "\n",
    "    if not epochs_to_plot:\n",
    "        print(\"\\n⚠️ Não há dados suficientes para gerar os gráficos.\")\n",
    "    else:\n",
    "        # --- GRÁFICO: Loss por Época (Treino vs Validação) ---\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # Subplot 1: Train Loss\n",
    "        ax1.plot(epochs_to_plot, train_losses_plot,\n",
    "                 marker='x', linestyle='--', linewidth=2, markersize=6,\n",
    "                 color='blue', label='Train Loss')\n",
    "        ax1.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax1.set_title(\"Perda de Treino por Época\", fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # Subplot 2: Validation Loss\n",
    "        ax2.plot(epochs_to_plot, val_losses_plot,\n",
    "                 marker='o', linestyle='-', linewidth=2, markersize=6,\n",
    "                 color='red', label='Validation Loss')\n",
    "        ax2.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax2.set_title(\"Perda de Validação por Época\", fontsize=14, fontweight='bold')\n",
    "        ax2.legend(fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ TREINAMENTO CONCLUÍDO COM SUCESSO!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\n❌ Erro durante o treinamento ou avaliação:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFSsNAWvaQQs"
   },
   "source": [
    "# **6. AVALIAÇÃO FINAL NO TESTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "0a5gLzc6aQuU",
    "outputId": "8680eadf-80ce-4d1a-899b-e785d9c458cf"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n==================== RESULTADOS FINAIS DO MODELO ====================\")\n",
    "print(\"\\nAvaliação no conjunto de teste:\")\n",
    "\n",
    "test_results = trainer.predict(test_dataset)\n",
    "final_metrics = test_results.metrics\n",
    "\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SLL_XiZaSle"
   },
   "source": [
    "# **7. SALVAR MODELO E DADOS DE RESULTADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbEnj8O5aUmx",
    "outputId": "3ac9e2c1-f0ad-4d77-f99b-74c0d9b0cd9f"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "print(\"Modelo salvo no Google Drive!\")\n",
    "\n",
    "# Salvar resultados do treinamento e rótulos/previsões finais\n",
    "output_results_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/resultados_fine_tuning.xlsx\"\n",
    "\n",
    "# Get the predictions from the test_results object\n",
    "predictions = np.argmax(test_results.predictions, axis=1)\n",
    "\n",
    "\n",
    "# Criar um DataFrame para os resultados de teste\n",
    "results_df = pd.DataFrame({\n",
    "    'texto': test_df['texto'],\n",
    "    'rotulo_verdadeiro': test_df['classe'],\n",
    "    'rotulo_predito_id': predictions,\n",
    "    'rotulo_predito': [id2label[p] for p in predictions]\n",
    "})\n",
    "\n",
    "# Salvar o DataFrame de resultados em um arquivo Excel\n",
    "results_df.to_excel(output_results_path, index=False)\n",
    "print(f\"Resultados de teste (texto, rótulo verdadeiro, rótulo predito) salvos em: {output_results_path}\")\n",
    "\n",
    "# Salvar as métricas finais em um arquivo de texto ou CSV\n",
    "metrics_output_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/metricas_finais.txt\"\n",
    "with open(metrics_output_path, 'w') as f:\n",
    "    f.write(\"Métricas Finais da Avaliação no Conjunto de Teste:\\n\")\n",
    "    for metric_name, value in final_metrics.items():\n",
    "        f.write(f\"{metric_name}: {value:.4f}\\n\")\n",
    "print(f\"Métricas finais salvas em: {metrics_output_path}\")\n",
    "\n",
    "# --- FIM DO CONTADOR DE TEMPO ---\n",
    "end_total_time = time.time()\n",
    "total_execution_time = end_total_time - start_total_time\n",
    "print(f\"\\nTempo total de execução do script: {total_execution_time:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
