{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kkt3yw00IoE"
   },
   "source": [
    "@inproceedings{souza2020bertimbau,\n",
    "  author    = {F{\\'a}bio Souza and\n",
    "               Rodrigo Nogueira and\n",
    "               Roberto Lotufo},\n",
    "  title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n",
    "  booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n",
    "  year      = {2020}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIfaYOAKr0R6"
   },
   "source": [
    "# **Conectando ao Google Drive**\n",
    "\n",
    "\n",
    "Para acessar e carregar os dados necessários para o projeto, montamos o Google Drive. Isso permite que o notebook leia arquivos diretamente de uma pasta em sua conta, facilitando o gerenciamento e a persistência dos dados entre diferentes sessões. O comando a seguir solicita permissão para conectar o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey0-HM5ocnvu",
    "outputId": "f434c662-2584-432b-c3a6-5fe9c904b2ea"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcTbLWwTr74s",
    "outputId": "ecef5f52-507f-4e66-c5af-9236a2e7d0e4"
   },
   "outputs": [],
   "source": [
    "!pip install transformers evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feHRGfqdONsa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "start_total_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkRUcLU1PHke"
   },
   "source": [
    "# **1. Carregar Dataset Processado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ti1knC9saC_"
   },
   "source": [
    "Nesta etapa, o conjunto de dados é preparado para o treinamento do modelo. O ***arquivo denuncias_balanceadas.xlsx*** é dividido em três partes: treino (70%), validação (15%) e teste (15%), garantindo que cada conjunto tenha uma distribuição similar das classes ***invasao_domicilio*** e ***violencia_fisica***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O3x60E3PHtT",
    "outputId": "74e59b3f-2683-4c12-bce6-60097df91137"
   },
   "outputs": [],
   "source": [
    "# Carregar dataset já processado\n",
    "file_path = '/content/drive/MyDrive/2025/tcc-final/denuncias_balanceadas.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Dividir em treino (70%), validação (15%) e teste (15%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['classe'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['classe'], random_state=42)\n",
    "\n",
    "print(f\"Treino: {len(train_df)}, Validação: {len(val_df)}, Teste: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3WAEgOPYHa"
   },
   "source": [
    "# **2. Tokenização com BERTimbau**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcpyLSPJstl_"
   },
   "source": [
    "Para que o modelo BERTimbau entenda nossos textos, é preciso convertê-los em um formato numérico. Este processo, chamado de tokenização, utiliza o ***AutoTokenizer*** do modelo BERTimbau, que é um modelo de linguagem pré-treinado especificamente para o português do Brasil. O ***tokenizer*** quebra os textos em ***tokens*** (palavras ou partes de palavras) e os mapeia para números que o modelo pode processar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324,
     "referenced_widgets": [
      "82f078a7666b4c8e8fcf6eaa0a95d6b9",
      "a2687792e2d8483fba013aa58bd36978",
      "a60507a392614e24ae84538413836f2f",
      "ce3e48db15ba49238caaa06fc3dcf60c",
      "098e10302535492e87265f33300bb8eb",
      "51d272269b404265bc8e0c750591ac21",
      "38aab554e2244cccbb6e181b3ea2cf02",
      "68300deef4c6422bb31f86c61e03b2da",
      "5a72cf8e087e4eeeb6b02ce280c642f5",
      "725d0ad548004ff197de3a8ba6b24078",
      "2fbf4c4f2575455ca80eb8912ac6d461",
      "211963058a3449248d78e4d93373c2e6",
      "c8cad1378c8340a28f1c84d9c5d4cc2d",
      "e70dde6df8474b579de7ff3d801c30b2",
      "1a8beab0990d4b12b8772d9f14eacb83",
      "e50bf59b973c4a0db3db5c165701e760",
      "97fddd24c93a46d1884eac03d4d6eddd",
      "9bf47e95ba8f4a748a20a152b26f4359",
      "472694253615412c855c5107cf7dcc11",
      "993e5a6a353f4201b92ea0cbd56455d8",
      "024b47252297425abf4d30b6c07f79e4",
      "6d7460fa77094f09a1752766f881db51",
      "d2dbfe9e103145ed83e6e4e1fcda3a09",
      "215c6040d0c44be4a45066a29109b434",
      "8c849bc7759343a6975a87d5ada0aa92",
      "a94648eb6eae4b8c9307ea4c73f61bb3",
      "b79f28fb339b43558f4fef07a201060a",
      "792795319bf04fbd8925489e26b8ddc3",
      "af70b8dba992433f9bd045caa9eb881d",
      "d75d1cf6ed2d4c9aaac1f7caf544f797",
      "33cf67e81fcb4cdf99c2df4a698fb202",
      "353ea1fc7b5c4f9a959625ee92697920",
      "b7f2835e99624311893eda1ae1f274fc",
      "fdcfa5c30a1a40578bff04b9140c6da3",
      "94a256e7c9c4412cb5c936df9f1e5818",
      "34fea07d8e104860b0a766de946438b9",
      "101d726420a7465e94b41c402d483eaf",
      "c1d5644dcbe3414ea7aae67dddfb0654",
      "409d6ef46d994f7497d44ac2b3828360",
      "ece191d9cd6a4e2bb4c10f0dc8800de2",
      "aee0e95c60714a398fdbe1e9d04d2919",
      "586f19fea01c476c97b9c30c1d5933a0",
      "7e8e6b28d18d4e60b136f73356a30ba4",
      "b5f31b945ece41a9a5d28e5ecce3dee8",
      "87221bc7f3404f9e9fa77ef4100b97d0",
      "f4adbdafa1a64c8585282e1c1114eaf3",
      "717ae42d0f8c44739e3b2816738e9bdf",
      "3d6584ae085b463ea4f9ce9d533d127b",
      "d0f8c5099a8847fc9a1a103dcd274250",
      "580ac02beaba4dffb26acb21683d7ee3",
      "de612f9467734e489aeada7725978b8d",
      "a02d33cb0a1b4070b6343eb1ee683543",
      "f24a7e746b8342a7abe13aebc659a2e1",
      "db4467cb7c7942238ba4d7de59d62a07",
      "969310dfa4fe46299796a46fd6a6a492"
     ]
    },
    "id": "sql7RSXMPd1g",
    "outputId": "0766491e-37c1-4749-a1e3-70433fcbcd06"
   },
   "outputs": [],
   "source": [
    "model_path = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Função de tokenização\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"texto\"], truncation=True,max_length=512, padding='longest',return_tensors='pt')\n",
    "\n",
    "# Tokenizar os DataFrames diretamente (sem usar datasets.Dataset)\n",
    "train_encodings = tokenize_function(train_df.to_dict('list'))\n",
    "val_encodings = tokenize_function(val_df.to_dict('list'))\n",
    "test_encodings = tokenize_function(test_df.to_dict('list'))\n",
    "print(train_encodings[0])\n",
    "print(val_encodings[0])\n",
    "print(test_encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0mzN3JPP-s4"
   },
   "source": [
    "# **3. Configuração do Modelo: Adaptando o BERTimbau para a nossa tarefa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKh_g5Rfs27y"
   },
   "source": [
    "Aqui, carregamos o modelo BERTimbau pré-treinado e o adaptamos para a nossa tarefa de classificação de texto. A parte mais importante desta etapa é a configuração da camada final (chamada de ***classifier***), que será treinada para prever uma de nossas duas classes. Além disso, congelamos as camadas de base do BERT, o que significa que apenas a nova camada do classificador será ajustada, otimizando o treinamento para um conjunto de dados menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "2e3aada0abc9441abc0af81a9dee728b",
      "ad42fffdf6fb4a61b47f8916ed419bae",
      "83c5405cee8b4c15bc27f9af295b1649",
      "444ae27b64094f96b83ae79c30cc651b",
      "3b0f082835a34c83bbc6119fa5b3ae87",
      "b0eec78c22154762ae0c7853bc66f24a",
      "bdcb94a16a004c9fa44ecc2a7a83ea05",
      "a98adc012b7e4c56bb26e85c71e02362",
      "760c21a2adba4e309b708af3c136b9c2",
      "75ac60368f7f4905ac2b1db56248f35a",
      "f3eaeb58a74041dfbedce03d6aa4dd06"
     ]
    },
    "id": "tkQIL_4sYTMq",
    "outputId": "f6d9ee75-10e9-4f99-c817-e972e7ef59d0"
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"invasao_domicilio\", 1: \"violencia_fisica\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Congelar camadas do BERT (exceto pooler e classificador)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name and 'pooler' not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S-nz2HQZ0CA"
   },
   "source": [
    "# **4. Avaliação do Modelo: Definindo as métricas de sucesso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38r3L7Pbs9xI"
   },
   "source": [
    "Para saber se o nosso modelo está aprendendo bem, precisamos de métricas de avaliação. Além da ***acurácia*** (a porcentagem de acertos), calculamos outras métricas importantes, como a ***AUC-ROC***, que mede a capacidade do modelo de distinguir entre as classes, e a ***Precisão, Recall e F1-Score***, que nos dão uma visão mais detalhada sobre o desempenho do modelo em cada classe (invasão de domicílio e violência física)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "5548ca7b18f545bb8e1bfd3c4eb58bb0",
      "bb078aa4a7b6476a83c1c0c8983ee959",
      "a5d64309504d4992943e62b64d90a1d5",
      "b4bc4082b39042a6b7d7fd95b1b90e79",
      "6c9a481bd895461d83590d0bee18cdf1",
      "83529a66be0d4dcf9f92d0f16d08ddf7",
      "58f5ade09a9f47debf126ec215583810",
      "4ddb484c83674b3c87bba15327b60ffc",
      "dc2da2e013af458ba807b8e816643d3d",
      "d78478a1e4e540c9ae57ca70876cd1c6",
      "3908632a500f468e8e85f153d92ceb7d",
      "23b8921f28ac40f8ba59e024f952ff21",
      "d9fa19264c01420f8debe18505414bbe",
      "295e128165d3416b8825f62a6b463b14",
      "414d05b06ceb447492d603365ec89d2b",
      "66c482c17e0a4d0ab0bbb1ee425efcf1",
      "2abb506f57d64cc58e42b58eafebafb3",
      "ffe3502f8d2442179883ced39b501e97",
      "04da2f1f977f4a7786ecdd4c57ed3e62",
      "27df52f637cf4f2ba737957c2499016a",
      "da7237294dc5417b9b8cedd00bbef1e5",
      "1513df745fcd4e51bd108dae3ccd6c8f",
      "64c7716a9e4b46e7a70dbd49221c5013",
      "12eec0ddae77445bb973600a09f6b7c5",
      "2c9e54cac53d478381dddc7cfde41fce",
      "c119c3c649354adc9825a5455ce3565b",
      "e3c021ac64ce4bbd8e519283b72e3baa",
      "6e690327556d49c684d0dc06778849e8",
      "dbbd070cf7704e04bf12e57622777e13",
      "355e786408ed48ffbaafc9c7f59efb9f",
      "16d527f78ab445278b775dd91774395e",
      "d8a76a1d26ed455b88047403bf2e42ad",
      "23bfda7e2d164c9799113010a81c4bef",
      "b0a2c90ff5b149b3b71c8674740779d4",
      "d68b0aa5b0b64d088708e209fc048fa0",
      "34ec2135de294b06831c87d4ea7feb45",
      "5e2976af3c56456ea8c1cdeede031af4",
      "e6f6d44d6fdd4daf9ef55be531f1a1df",
      "65d748f0291b44d2ad34f79528ec087d",
      "34f536e5abfe4503924d94dfafa46da9",
      "93b2a95dee0742578a3c546ded18151f",
      "7111dc34b69a4fcfb3dada282b0c57a4",
      "38eeebd169c54634993677cd5e7f5a28",
      "2a7bdbbeb5664f64823492520c5043f5",
      "b231d13021dd48dfa1aeb8d08bb2a892",
      "3fd339e845474cad83f716740e69f03d",
      "34b6874a41264a24a61f0797ae2e58bb",
      "e5195b7ede9540abb495b85e94777cd6",
      "2955e24bda4d4ac1b6125960bf2ef6e4",
      "a7a5c28c04c948119f0b2ef7122cf706",
      "46ace2105a2c4d249b3f1e12a67dbb68",
      "880658254b5c46b1b61875002c98f247",
      "bb2a9314f76e483095cecbad71bb3141",
      "20b1c8b265b34ba2a6a061dd38da5431",
      "e16a6b50df7a4c16b7ea8befa4e2fd68",
      "0dc430306ca64313aeb4a23ad6781101",
      "777efba1b8c649c7a1db43d8fdcfbb79",
      "7939a47435a247a0a9823a0f3c08315c",
      "2a4160f7de0e49cabf3ab87f61863b13",
      "ec72a5fa03a5454b99c4668d3763326a",
      "6716f9f3682d45a59e39febce46edf75",
      "a58c032ff37445ec84632e532e3d0dd7",
      "bca14952bfe0486b81e9722b110e1278",
      "302f0554621f43888a1b34d173d9493d",
      "14cc33fe002c49d5ad1525af77b4037b",
      "03a09e30e0b14db791b0a0e66c400357"
     ]
    },
    "id": "F-gctrIbZ1Pv",
    "outputId": "68455d1a-bb5e-415d-b4f7-f3b726398963"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    try:\n",
    "        predictions, labels = eval_pred\n",
    "        probabilities = np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)) / np.sum(np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)), axis=-1, keepdims=True)\n",
    "        positive_class_probs = probabilities[:, 1]\n",
    "\n",
    "        preds = np.argmax(predictions, axis=1)\n",
    "        acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "        auc = auc_score.compute(prediction_scores=positive_class_probs, references=labels)[\"roc_auc\"]\n",
    "\n",
    "        f1_results = f1_metric.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        precision_results = precision.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        recall_results = recall.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": round(acc, 4),\n",
    "            \"auc\": round(auc, 4),\n",
    "            \"f1_invasao\": round(f1_results[\"f1\"][0], 4),\n",
    "            \"f1_violencia\": round(f1_results[\"f1\"][1], 4),\n",
    "            \"precision_invasao\": round(precision_results[\"precision\"][0], 4),\n",
    "            \"precision_violencia\": round(precision_results[\"precision\"][1], 4),\n",
    "            \"recall_invasao\": round(recall_results[\"recall\"][0], 4),\n",
    "            \"recall_violencia\": round(recall_results[\"recall\"][1], 4),\n",
    "            \"precision_macro\": round(np.mean(precision_results[\"precision\"]), 4),\n",
    "            \"recall_macro\": round(np.mean(recall_results[\"recall\"]), 4),\n",
    "            \"f1_macro\": round(np.mean(f1_results[\"f1\"]), 4)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no cálculo de métricas: {str(e)}\")\n",
    "        return {\"accuracy\": 0.0, \"auc\": 0.0, \"f1_invasao\": 0.0, \"f1_violencia\": 0.0,\n",
    "                \"precision_invasao\": 0.0, \"precision_violencia\": 0.0,\n",
    "                \"recall_invasao\": 0.0, \"recall_violencia\": 0.0,\n",
    "                \"precision_macro\": 0.0, \"recall_macro\": 0.0, \"f1_macro\": 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwkxUjbiuniC"
   },
   "source": [
    "# **5. Treinamento: A mágica do Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6u5QzNauoN1"
   },
   "source": [
    "Nesta seção, iniciamos o treinamento do modelo usando a biblioteca ***Hugging Face Trainer***. O treinamento será executado por 30 épocas. O ***EarlyStoppingCallback*** é ativado para interromper o treinamento caso o desempenho do modelo no conjunto de validação pare de melhorar por três épocas consecutivas, evitando o overfitting. Você pode acompanhar a evolução da perda (loss) e da acurácia durante o processo no gráfico abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FZYLPL15MDKG",
    "outputId": "477805b8-84f7-4a67-ac28-6b8873c4c7bf"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "# Listas para armazenar métricas para plotagem\n",
    "train_losses_plot, val_losses_plot = [], []\n",
    "train_accuracies_plot, val_accuracies_plot = [], []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuração dos argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertimbau-denuncias\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=30,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Data Collator para padding dinâmico\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Custom Dataset (para trabalhar com DataFrames)\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels.values if isinstance(labels, pd.Series) else labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Criar datasets\n",
    "print(\"\\n📊 Preparando datasets...\")\n",
    "train_dataset = CustomDataset(train_encodings, train_df['classe'].map(label2id).tolist())\n",
    "val_dataset = CustomDataset(val_encodings, val_df['classe'].map(label2id).tolist())\n",
    "test_dataset = CustomDataset(test_encodings, test_df['classe'].map(label2id).tolist())\n",
    "\n",
    "print(f\"✅ Datasets criados:\")\n",
    "print(f\"   • Treino: {len(train_dataset)} amostras\")\n",
    "print(f\"   • Validação: {len(val_dataset)} amostras\")\n",
    "print(f\"   • Teste: {len(test_dataset)} amostras\")\n",
    "\n",
    "# Instanciar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=1e-3)],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 INICIANDO TREINAMENTO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Treinar o modelo\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    # --- EXTRAIR MÉTRICAS DOS LOGS PARA OS GRÁFICOS ---\n",
    "    print(\"\\n📊 Coletando métricas de treinamento...\")\n",
    "    logs = trainer.state.log_history\n",
    "\n",
    "    # Limpar listas (caso esteja rodando múltiplas vezes)\n",
    "    train_losses_plot = []\n",
    "    val_losses_plot = []\n",
    "    train_accuracies_plot = []\n",
    "    val_accuracies_plot = []\n",
    "\n",
    "    # Iterar sobre os logs para preencher as listas\n",
    "    for log_entry in logs:\n",
    "        # Perdas de Treino: o 'loss' é logado para o treinamento\n",
    "        if 'loss' in log_entry and 'eval_loss' not in log_entry:\n",
    "            train_losses_plot.append(log_entry['loss'])\n",
    "\n",
    "        # Métricas de Validação: logadas com prefixo 'eval_'\n",
    "        if 'eval_loss' in log_entry and 'eval_accuracy' in log_entry:\n",
    "            val_losses_plot.append(log_entry['eval_loss'])\n",
    "            val_accuracies_plot.append(log_entry['eval_accuracy'])\n",
    "\n",
    "    # Diagnóstico\n",
    "    print(f\"\\n📊 Métricas coletadas:\")\n",
    "    print(f\"   • Train losses: {len(train_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation losses: {len(val_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation accuracies: {len(val_accuracies_plot)} épocas\")\n",
    "\n",
    "    # ⚠️ GARANTIR MESMO TAMANHO\n",
    "    min_length = min(len(train_losses_plot), len(val_losses_plot))\n",
    "    if len(train_losses_plot) != len(val_losses_plot):\n",
    "        print(f\"   ⚠️ AVISO: Tamanhos diferentes! Ajustando para {min_length} épocas\")\n",
    "        train_losses_plot = train_losses_plot[:min_length]\n",
    "        val_losses_plot = val_losses_plot[:min_length]\n",
    "        val_accuracies_plot = val_accuracies_plot[:min_length]\n",
    "\n",
    "    # Métricas finais de treino\n",
    "    print(f\"\\n📊 Métricas finais de treino:\")\n",
    "    print(f\"   Loss: {train_results.metrics.get('train_loss', 'N/A'):.4f}\")\n",
    "    print(f\"   Tempo total: {train_results.metrics.get('train_runtime', 'N/A'):.2f}s\")\n",
    "\n",
    "    # ✅ CALCULAR TRAIN ACCURACY\n",
    "    print(f\"\\n📊 Calculando Train Accuracy...\")\n",
    "    train_predictions_output = trainer.predict(train_dataset)\n",
    "    train_predictions = np.argmax(train_predictions_output.predictions, axis=1)\n",
    "    train_labels_array = train_predictions_output.label_ids\n",
    "    train_accuracy_final = (train_predictions == train_labels_array).mean()\n",
    "    print(f\"   Train Accuracy: {train_accuracy_final:.4f}\")\n",
    "\n",
    "    # Avaliação no conjunto de VALIDAÇÃO\n",
    "    print(f\"\\n🔍 Avaliação no conjunto de VALIDAÇÃO...\")\n",
    "    val_metrics = trainer.evaluate(val_dataset)\n",
    "    print(f\"   Resultados de validação:\")\n",
    "    for key, value in val_metrics.items():\n",
    "        print(f\"      • {key}: {value:.4f}\")\n",
    "\n",
    "    # ✅ CALCULAR GAP\n",
    "    final_train_loss = train_results.metrics.get('train_loss', 0)\n",
    "    final_val_loss = val_metrics.get('eval_loss', 0)\n",
    "    gap = final_val_loss - final_train_loss\n",
    "    gap_pct = (gap / final_train_loss) * 100 if final_train_loss > 0 else 0\n",
    "\n",
    "    print(f\"\\n📏 Análise de GAP:\")\n",
    "    print(f\"   Train Loss: {final_train_loss:.6f}\")\n",
    "    print(f\"   Val Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"   GAP: {gap:.6f} ({gap_pct:.2f}%)\")\n",
    "    if gap < 0.10:\n",
    "        print(f\"   Status: ✅ Bom\")\n",
    "    elif gap < 0.15:\n",
    "        print(f\"   Status: ⚠️ Atenção\")\n",
    "    else:\n",
    "        print(f\"   Status: 🚨 Overfitting\")\n",
    "\n",
    "    # --- 📊 GRÁFICOS DE COMPARAÇÃO POR ÉPOCA ---\n",
    "    print(f\"\\n📊 Gerando gráficos...\")\n",
    "\n",
    "    epochs_completed = min_length\n",
    "    epochs_to_plot = list(range(1, epochs_completed + 1))\n",
    "\n",
    "    if not epochs_to_plot:\n",
    "        print(\"\\n⚠️ Não há dados suficientes para gerar os gráficos.\")\n",
    "    else:\n",
    "        # --- GRÁFICO: Loss por Época (Treino vs Validação) ---\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # Subplot 1: Train Loss\n",
    "        ax1.plot(epochs_to_plot, train_losses_plot,\n",
    "                 marker='x', linestyle='--', linewidth=2, markersize=6,\n",
    "                 color='blue', label='Train Loss')\n",
    "        ax1.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax1.set_title(\"Perda de Treino por Época\", fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # Subplot 2: Validation Loss\n",
    "        ax2.plot(epochs_to_plot, val_losses_plot,\n",
    "                 marker='o', linestyle='-', linewidth=2, markersize=6,\n",
    "                 color='red', label='Validation Loss')\n",
    "        ax2.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax2.set_title(\"Perda de Validação por Época\", fontsize=14, fontweight='bold')\n",
    "        ax2.legend(fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ TREINAMENTO CONCLUÍDO COM SUCESSO!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\n❌ Erro durante o treinamento ou avaliação:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFSsNAWvaQQs"
   },
   "source": [
    "# **6. AVALIAÇÃO FINAL NO TESTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "0a5gLzc6aQuU",
    "outputId": "077a6668-d9ae-42e5-b5f0-d95e0b3d87a4"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n==================== RESULTADOS FINAIS DO MODELO ====================\")\n",
    "print(\"\\nAvaliação no conjunto de teste:\")\n",
    "\n",
    "test_results = trainer.predict(test_dataset)\n",
    "final_metrics = test_results.metrics\n",
    "\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SLL_XiZaSle"
   },
   "source": [
    "# **7. SALVAR MODELO E DADOS DE RESULTADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbEnj8O5aUmx",
    "outputId": "274d0c73-044b-40ad-a045-bdde7d82dc2e"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "print(\"Modelo salvo no Google Drive!\")\n",
    "\n",
    "# Salvar resultados do treinamento e rótulos/previsões finais\n",
    "output_results_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/resultados_fine_tuning.xlsx\"\n",
    "\n",
    "# Get the predictions from the test_results object\n",
    "predictions = np.argmax(test_results.predictions, axis=1)\n",
    "\n",
    "\n",
    "# Criar um DataFrame para os resultados de teste\n",
    "results_df = pd.DataFrame({\n",
    "    'texto': test_df['texto'],\n",
    "    'rotulo_verdadeiro': test_df['classe'],\n",
    "    'rotulo_predito_id': predictions,\n",
    "    'rotulo_predito': [id2label[p] for p in predictions]\n",
    "})\n",
    "\n",
    "# Salvar o DataFrame de resultados em um arquivo Excel\n",
    "results_df.to_excel(output_results_path, index=False)\n",
    "print(f\"Resultados de teste (texto, rótulo verdadeiro, rótulo predito) salvos em: {output_results_path}\")\n",
    "\n",
    "# Salvar as métricas finais em um arquivo de texto ou CSV\n",
    "metrics_output_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/metricas_finais.txt\"\n",
    "with open(metrics_output_path, 'w') as f:\n",
    "    f.write(\"Métricas Finais da Avaliação no Conjunto de Teste:\\n\")\n",
    "    for metric_name, value in final_metrics.items():\n",
    "        f.write(f\"{metric_name}: {value:.4f}\\n\")\n",
    "print(f\"Métricas finais salvas em: {metrics_output_path}\")\n",
    "\n",
    "# --- FIM DO CONTADOR DE TEMPO ---\n",
    "end_total_time = time.time()\n",
    "total_execution_time = end_total_time - start_total_time\n",
    "print(f\"\\nTempo total de execução do script: {total_execution_time:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
