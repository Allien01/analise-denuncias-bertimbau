{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Kkt3yw00IoE"
   },
   "source": [
    "@inproceedings{souza2020bertimbau,\n",
    "  author    = {F{\\'a}bio Souza and\n",
    "               Rodrigo Nogueira and\n",
    "               Roberto Lotufo},\n",
    "  title     = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese},\n",
    "  booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)},\n",
    "  year      = {2020}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIfaYOAKr0R6"
   },
   "source": [
    "# **Conectando ao Google Drive**\n",
    "\n",
    "\n",
    "Para acessar e carregar os dados necessários para o projeto, montamos o Google Drive. Isso permite que o notebook leia arquivos diretamente de uma pasta em sua conta, facilitando o gerenciamento e a persistência dos dados entre diferentes sessões. O comando a seguir solicita permissão para conectar o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ey0-HM5ocnvu",
    "outputId": "82f82b31-ac72-477d-8943-bbf80617cc8e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcTbLWwTr74s",
    "outputId": "da4869a7-03d9-4a0d-f058-16802ffff03e"
   },
   "outputs": [],
   "source": [
    "!pip install transformers evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feHRGfqdONsa"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "start_total_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkRUcLU1PHke"
   },
   "source": [
    "# **1. Carregar Dataset Processado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ti1knC9saC_"
   },
   "source": [
    "Nesta etapa, o conjunto de dados é preparado para o treinamento do modelo. O ***arquivo denuncias_balanceadas.xlsx*** é dividido em três partes: treino (70%), validação (15%) e teste (15%), garantindo que cada conjunto tenha uma distribuição similar das classes ***invasao_domicilio*** e ***violencia_fisica***.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O3x60E3PHtT",
    "outputId": "e036f01d-3a7a-4729-8c1f-307b80b84564"
   },
   "outputs": [],
   "source": [
    "# Carregar dataset já processado\n",
    "file_path = '/content/drive/MyDrive/2025/tcc-final/denuncias_balanceadas.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Dividir em treino (70%), validação (15%) e teste (15%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['classe'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['classe'], random_state=42)\n",
    "\n",
    "print(f\"Treino: {len(train_df)}, Validação: {len(val_df)}, Teste: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3WAEgOPYHa"
   },
   "source": [
    "# **2. Tokenização com BERTimbau**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcpyLSPJstl_"
   },
   "source": [
    "Para que o modelo BERTimbau entenda nossos textos, é preciso convertê-los em um formato numérico. Este processo, chamado de tokenização, utiliza o ***AutoTokenizer*** do modelo BERTimbau, que é um modelo de linguagem pré-treinado especificamente para o português do Brasil. O ***tokenizer*** quebra os textos em ***tokens*** (palavras ou partes de palavras) e os mapeia para números que o modelo pode processar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324,
     "referenced_widgets": [
      "526dd279b0484147a1b8987155564b9e",
      "08784d25b2db41d6a4b43167181fedb9",
      "0796bb0f52644aa897404b5e334a8b82",
      "d297e70eabdd434e9e89a518dee6da8a",
      "bc7183b04e164c08b982a6d13c9be302",
      "c9909097564d46cbb06220cf1cd066eb",
      "6f55dde8490d4e49aa3c2f757ef488c7",
      "ca782774f2104bc1ba6d0381df6e3a5d",
      "1386b939dd2148c09cb06f22b81208a2",
      "30a06082ee124b348a9c5d9c9ac1852f",
      "dd402b4ef79e4b4eb16729167eca2e18",
      "b29c922147b541c48bffd3aa1d2fdb59",
      "5286fde01eb14989bbd55da7a985fd49",
      "06d8a348e1a143358707d77bda80e02a",
      "110005ebc08c4baca5f922afa9f5f488",
      "6b8134084c4c4b4f970e163faaf61af4",
      "6821690a478b49eeae975275cb76d9cc",
      "24272a210b5144d2b29d0bfa99a596be",
      "849adbb57ddc43cc8f1b2463f5d85146",
      "2142a1a7708e4782bb96b82a62d3d1c6",
      "6d9cbf7fb62d41889fdb402b7623c83a",
      "a692b4b77c1a4bf28d3a41cdc5f967ac",
      "7ce52401daec4e1ab9f01bea10cc8853",
      "1adb0a02f6cd4cfba325f3222f8c62cf",
      "bd6a398a4c7042579ce17cfdf9d127a2",
      "0d7d5758c3844ff2942956fe64edc066",
      "4b8610fbce33445295171269fbb964c3",
      "dade0c9fe6e14976970197a61eec9a96",
      "7c46416c2547447c9ed2ac2bd5c33470",
      "b5e17a47405e4ade9f50fa3f18ee52a9",
      "a576839448ff4ffd99bf4788bc4dbc28",
      "bc409b2e93e54b7284c2f2d84e6a38aa",
      "3c298710237344eab7254bf0e3918681",
      "24b4ea1bbc8040e38ed88a917baa78f0",
      "cb9a4e5fcd5f43e98ed261dfc9109ad3",
      "90685980c4104e2880d96aa2acfb972e",
      "ab0c844c4adf48969ed26e11feb29d7f",
      "a853eb8510f149f791eab73453072196",
      "2114ee86d76b454ba64fba8e50a742ea",
      "f9f52f457f6040539c823a9b4c2e1319",
      "23426fc8deb841208467132c8a5ef966",
      "c06f60c2eef448eea54b47615437a9e7",
      "e19feea88ee5477a958880c112acb542",
      "9e6c5785940043f39e8cd6bb3080093e",
      "248b3be658af4e98b1c959e868b58d19",
      "7b93558327284ddb8f839e633146712c",
      "e8a53138d126432bb16d50be692f6b0e",
      "489f500482c54e098a1e30c1f03fcc0a",
      "f6d2d98e403f4c10b8e31db5192946e6",
      "d9a678fc82bb4c58b207d98c3a972900",
      "5cee5da0284b4e59b7027196dbc78bd0",
      "29f9598daf014cc68ff61c6d8524154b",
      "8fea081d7ebb4e15b563fe7510c1fc6b",
      "f62fd60237e9440a90dc647789efd85a",
      "ded23810a062421c9fb8dda8e515ea98"
     ]
    },
    "id": "sql7RSXMPd1g",
    "outputId": "5a8c279a-554e-4eeb-983f-e969be0ea523"
   },
   "outputs": [],
   "source": [
    "model_path = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# Função de tokenização\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"texto\"], truncation=True,max_length=512, padding='longest',return_tensors='pt')\n",
    "\n",
    "# Tokenizar os DataFrames diretamente (sem usar datasets.Dataset)\n",
    "train_encodings = tokenize_function(train_df.to_dict('list'))\n",
    "val_encodings = tokenize_function(val_df.to_dict('list'))\n",
    "test_encodings = tokenize_function(test_df.to_dict('list'))\n",
    "print(train_encodings[0])\n",
    "print(val_encodings[0])\n",
    "print(test_encodings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U0mzN3JPP-s4"
   },
   "source": [
    "# **3. Configuração do Modelo: Adaptando o BERTimbau para a nossa tarefa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKh_g5Rfs27y"
   },
   "source": [
    "Aqui, carregamos o modelo BERTimbau pré-treinado e o adaptamos para a nossa tarefa de classificação de texto. A parte mais importante desta etapa é a configuração da camada final (chamada de ***classifier***), que será treinada para prever uma de nossas duas classes. Além disso, congelamos as camadas de base do BERT, o que significa que apenas a nova camada do classificador será ajustada, otimizando o treinamento para um conjunto de dados menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "8b389f3542864e979ffa2d58ae644997",
      "3bb74c12df4f49cfb1f28bc11ec1aae7",
      "7e8c250cb0024e90b56d22a341b3dd12",
      "952124c8b6324ad5aac271db898f8fe9",
      "8adaad22d5b34c818db5f80b5936321d",
      "e2c32ece89a247e19ea6bc7d67b9f6df",
      "269efd90a7c6482692f58d24e86f7c5a",
      "133a613a3aed424580ff585d31f329f9",
      "56bc0c8703384ae4a02681e3274d7c67",
      "669dc3ec7ab247e7ad89101fe1693b48",
      "4f472753f1774b779b6b0f0e996c6d31"
     ]
    },
    "id": "tkQIL_4sYTMq",
    "outputId": "f18b5fd2-8801-4f28-ae48-5a9d81ad54ac"
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"invasao_domicilio\", 1: \"violencia_fisica\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_path,\n",
    "    num_labels=2,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "# Congelar camadas do BERT (exceto pooler e classificador)\n",
    "for name, param in model.named_parameters():\n",
    "    if 'classifier' not in name and 'pooler' not in name:\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S-nz2HQZ0CA"
   },
   "source": [
    "# **4. Avaliação do Modelo: Definindo as métricas de sucesso**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38r3L7Pbs9xI"
   },
   "source": [
    "Para saber se o nosso modelo está aprendendo bem, precisamos de métricas de avaliação. Além da ***acurácia*** (a porcentagem de acertos), calculamos outras métricas importantes, como a ***AUC-ROC***, que mede a capacidade do modelo de distinguir entre as classes, e a ***Precisão, Recall e F1-Score***, que nos dão uma visão mais detalhada sobre o desempenho do modelo em cada classe (invasão de domicílio e violência física)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "10e108f616b04f96a10e9e224c1f4496",
      "45cac18ad78b444e9585f49080c4bdcc",
      "6160d0abce5943ad85bb9ca0b7bd1cd1",
      "329644cced664da3bf3a4952325e6c4f",
      "dde5d845caf24514a77ae19807d3af3f",
      "21ac386c8f0540548e23351e7607b6f6",
      "5e0d516c3acc40e7bd697a0d614e0693",
      "2f621c1451e7405e89b2ef0fbab7e228",
      "d2a5c53106d94d7198e586703e084bd6",
      "b98babfd80fb4708a523d04da93d368f",
      "7689df9ce0dd4e14b2f9ee47356d1e7d",
      "91cabbc5c88142d3b51eed852b9542dc",
      "c6b3b18beb1c49c3b838bdb2a4c7ab84",
      "cdac77fb74104a6abc73faf15ab7eaae",
      "b5a152e5e1f24f6e9f6a6a42d5222689",
      "0965358c41614bd7be9835c7af5ee8cd",
      "636566cf33e6433d9fa891b73759078d",
      "6e188a35470740fd9175fbbf299bdcb0",
      "79c924fbe5054203a4be172883538c16",
      "2ae40e4ec16347358efec26bc754fef0",
      "8b862816d3314a9ea02ca41b9bfa7e3f",
      "5c16181bbaf545589fc7be377ea1be3b",
      "49954916a15a4d5898e52378a72fd9ad",
      "ac1f1bdacedf4cf593cbade716951d58",
      "cae4215511954db8b9b8a22f01a23957",
      "fe008eda8f2f4ad18fc916fc0651c9d1",
      "79f41de734774714a1d47e7a46f5f0d5",
      "4418314e7f854b3ea31089b3d86e2c55",
      "bde3f5330d31440aab64194fb02e9346",
      "c0a17b4ccbd5436faa5e872e82197a81",
      "0cc34725b2c74a9da2513535c2c73ecc",
      "6627a1653bbe45d4be53c50cfa3fd815",
      "f824adbc6b024e428b7efa74d1d52c6f",
      "96f477a683af442fb5fa7409bd2a0a89",
      "f7615f2b0b1f416fb948369f7f1f0e82",
      "0d65422cbfcd4681a027991cadccb720",
      "b8cd647fe3c6463ba1b6c10c56ae456c",
      "78de119b247d4d87bfca25e6db135a9a",
      "8a087be7706f4b668f6537108b46a547",
      "65826fe2635a4da8bf7133ef66ec3548",
      "b98e25b75223418cb6c8005063fa70e9",
      "aa1d7c62f8cd4e5bad0d0d7d1a38e53b",
      "4f76a67eb0d44583a89671883ee04990",
      "45982d31c0af4bdfa6d7e77e37c6f22f",
      "4e11c6f5088f414aad70cff802f085f9",
      "2c8ce1d632ef49688b8f8964101b208d",
      "989ee7283e0148daa432a851bf6b7c8a",
      "598fecd1ebc54fb7839dbc5f64be4e64",
      "d84b06e0f92f4aff9cbf9dc4d1fff113",
      "c247338a59734833ad734dac0a412c19",
      "ea470192f6d941aa87708ce1104a31a7",
      "67c4824275784a60abbbffa7b6ff0d1c",
      "0188901fc71645679b3ab5cceb362104",
      "6f1f3d68bc434d20ab1712186883d062",
      "4f4de211d83046c2b6984d0542f70b8f",
      "1e8dc313d3674eedbac18a890e22a476",
      "cd84a51f3ac84c6aac7eae9b1f1c7085",
      "4dc1f5f7b1484b0b841ca7bbf47ea156",
      "5b812235953b404b8cca5a2c21f5edc4",
      "4212b80bcb384f9b847bdf85284f630f",
      "6b169803e5fe4cf9a78b448ee01377e3",
      "fe78fa1d4ac74ad7811b054bfa6ba02a",
      "e43295484f8b4284b691a5f7e1b888fb",
      "b8913ca73e7548fd9cfaf0453014cd82",
      "18ae63bf093c495db4265b36f657382b",
      "40c37343310c437daa86512053b29246"
     ]
    },
    "id": "F-gctrIbZ1Pv",
    "outputId": "fd55b85d-89a9-4506-d6ab-8a3d1fb2c5c5"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    try:\n",
    "        predictions, labels = eval_pred\n",
    "        probabilities = np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)) / np.sum(np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)), axis=-1, keepdims=True)\n",
    "        positive_class_probs = probabilities[:, 1]\n",
    "\n",
    "        preds = np.argmax(predictions, axis=1)\n",
    "        acc = accuracy.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "        auc = auc_score.compute(prediction_scores=positive_class_probs, references=labels)[\"roc_auc\"]\n",
    "\n",
    "        f1_results = f1_metric.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        precision_results = precision.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "        recall_results = recall.compute(\n",
    "            predictions=preds,\n",
    "            references=labels,\n",
    "            average=None,\n",
    "            labels=[label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": round(acc, 4),\n",
    "            \"auc\": round(auc, 4),\n",
    "            \"f1_invasao\": round(f1_results[\"f1\"][0], 4),\n",
    "            \"f1_violencia\": round(f1_results[\"f1\"][1], 4),\n",
    "            \"precision_invasao\": round(precision_results[\"precision\"][0], 4),\n",
    "            \"precision_violencia\": round(precision_results[\"precision\"][1], 4),\n",
    "            \"recall_invasao\": round(recall_results[\"recall\"][0], 4),\n",
    "            \"recall_violencia\": round(recall_results[\"recall\"][1], 4),\n",
    "            \"precision_macro\": round(np.mean(precision_results[\"precision\"]), 4),\n",
    "            \"recall_macro\": round(np.mean(recall_results[\"recall\"]), 4),\n",
    "            \"f1_macro\": round(np.mean(f1_results[\"f1\"]), 4)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no cálculo de métricas: {str(e)}\")\n",
    "        return {\"accuracy\": 0.0, \"auc\": 0.0, \"f1_invasao\": 0.0, \"f1_violencia\": 0.0,\n",
    "                \"precision_invasao\": 0.0, \"precision_violencia\": 0.0,\n",
    "                \"recall_invasao\": 0.0, \"recall_violencia\": 0.0,\n",
    "                \"precision_macro\": 0.0, \"recall_macro\": 0.0, \"f1_macro\": 0.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kwkxUjbiuniC"
   },
   "source": [
    "# **5. Treinamento: A mágica do Fine-Tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6u5QzNauoN1"
   },
   "source": [
    "Nesta seção, iniciamos o treinamento do modelo usando a biblioteca ***Hugging Face Trainer***. O treinamento será executado por 30 épocas. O ***EarlyStoppingCallback*** é ativado para interromper o treinamento caso o desempenho do modelo no conjunto de validação pare de melhorar por três épocas consecutivas, evitando o overfitting. Você pode acompanhar a evolução da perda (loss) e da acurácia durante o processo no gráfico abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FZYLPL15MDKG",
    "outputId": "74aa1630-2b25-47e7-df5a-f6392d23daa1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "\n",
    "# Listas para armazenar métricas para plotagem\n",
    "train_losses_plot, val_losses_plot = [], []\n",
    "train_accuracies_plot, val_accuracies_plot = [], []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Configuração dos argumentos de treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertimbau-denuncias\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=30,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    "    logging_dir=\"./logs\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Data Collator para padding dinâmico\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# Custom Dataset (para trabalhar com DataFrames)\n",
    "class CustomDataset(TorchDataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels.values if isinstance(labels, pd.Series) else labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Criar datasets\n",
    "print(\"\\n📊 Preparando datasets...\")\n",
    "train_dataset = CustomDataset(train_encodings, train_df['classe'].map(label2id).tolist())\n",
    "val_dataset = CustomDataset(val_encodings, val_df['classe'].map(label2id).tolist())\n",
    "test_dataset = CustomDataset(test_encodings, test_df['classe'].map(label2id).tolist())\n",
    "\n",
    "print(f\"✅ Datasets criados:\")\n",
    "print(f\"   • Treino: {len(train_dataset)} amostras\")\n",
    "print(f\"   • Validação: {len(val_dataset)} amostras\")\n",
    "print(f\"   • Teste: {len(test_dataset)} amostras\")\n",
    "\n",
    "# Instanciar o Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=1e-3)],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"🚀 INICIANDO TREINAMENTO\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    # Treinar o modelo\n",
    "    train_results = trainer.train()\n",
    "\n",
    "    # --- EXTRAIR MÉTRICAS DOS LOGS PARA OS GRÁFICOS ---\n",
    "    print(\"\\n📊 Coletando métricas de treinamento...\")\n",
    "    logs = trainer.state.log_history\n",
    "\n",
    "    # Limpar listas (caso esteja rodando múltiplas vezes)\n",
    "    train_losses_plot = []\n",
    "    val_losses_plot = []\n",
    "    train_accuracies_plot = []\n",
    "    val_accuracies_plot = []\n",
    "\n",
    "    # Iterar sobre os logs para preencher as listas\n",
    "    for log_entry in logs:\n",
    "        # Perdas de Treino: o 'loss' é logado para o treinamento\n",
    "        if 'loss' in log_entry and 'eval_loss' not in log_entry:\n",
    "            train_losses_plot.append(log_entry['loss'])\n",
    "\n",
    "        # Métricas de Validação: logadas com prefixo 'eval_'\n",
    "        if 'eval_loss' in log_entry and 'eval_accuracy' in log_entry:\n",
    "            val_losses_plot.append(log_entry['eval_loss'])\n",
    "            val_accuracies_plot.append(log_entry['eval_accuracy'])\n",
    "\n",
    "    # Diagnóstico\n",
    "    print(f\"\\n📊 Métricas coletadas:\")\n",
    "    print(f\"   • Train losses: {len(train_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation losses: {len(val_losses_plot)} épocas\")\n",
    "    print(f\"   • Validation accuracies: {len(val_accuracies_plot)} épocas\")\n",
    "\n",
    "    # ⚠️ GARANTIR MESMO TAMANHO\n",
    "    min_length = min(len(train_losses_plot), len(val_losses_plot))\n",
    "    if len(train_losses_plot) != len(val_losses_plot):\n",
    "        print(f\"   ⚠️ AVISO: Tamanhos diferentes! Ajustando para {min_length} épocas\")\n",
    "        train_losses_plot = train_losses_plot[:min_length]\n",
    "        val_losses_plot = val_losses_plot[:min_length]\n",
    "        val_accuracies_plot = val_accuracies_plot[:min_length]\n",
    "\n",
    "    # Métricas finais de treino\n",
    "    print(f\"\\n📊 Métricas finais de treino:\")\n",
    "    print(f\"   Loss: {train_results.metrics.get('train_loss', 'N/A'):.4f}\")\n",
    "    print(f\"   Tempo total: {train_results.metrics.get('train_runtime', 'N/A'):.2f}s\")\n",
    "\n",
    "    # ✅ CALCULAR TRAIN ACCURACY\n",
    "    print(f\"\\n📊 Calculando Train Accuracy...\")\n",
    "    train_predictions_output = trainer.predict(train_dataset)\n",
    "    train_predictions = np.argmax(train_predictions_output.predictions, axis=1)\n",
    "    train_labels_array = train_predictions_output.label_ids\n",
    "    train_accuracy_final = (train_predictions == train_labels_array).mean()\n",
    "    print(f\"   Train Accuracy: {train_accuracy_final:.4f}\")\n",
    "\n",
    "    # Avaliação no conjunto de VALIDAÇÃO\n",
    "    print(f\"\\n🔍 Avaliação no conjunto de VALIDAÇÃO...\")\n",
    "    val_metrics = trainer.evaluate(val_dataset)\n",
    "    print(f\"   Resultados de validação:\")\n",
    "    for key, value in val_metrics.items():\n",
    "        print(f\"      • {key}: {value:.4f}\")\n",
    "\n",
    "    # ✅ CALCULAR GAP\n",
    "    final_train_loss = train_results.metrics.get('train_loss', 0)\n",
    "    final_val_loss = val_metrics.get('eval_loss', 0)\n",
    "    gap = final_val_loss - final_train_loss\n",
    "    gap_pct = (gap / final_train_loss) * 100 if final_train_loss > 0 else 0\n",
    "\n",
    "    print(f\"\\n📏 Análise de GAP:\")\n",
    "    print(f\"   Train Loss: {final_train_loss:.6f}\")\n",
    "    print(f\"   Val Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"   GAP: {gap:.6f} ({gap_pct:.2f}%)\")\n",
    "    if gap < 0.10:\n",
    "        print(f\"   Status: ✅ Bom\")\n",
    "    elif gap < 0.15:\n",
    "        print(f\"   Status: ⚠️ Atenção\")\n",
    "    else:\n",
    "        print(f\"   Status: 🚨 Overfitting\")\n",
    "\n",
    "    # --- 📊 GRÁFICOS DE COMPARAÇÃO POR ÉPOCA ---\n",
    "    print(f\"\\n📊 Gerando gráficos...\")\n",
    "\n",
    "    epochs_completed = min_length\n",
    "    epochs_to_plot = list(range(1, epochs_completed + 1))\n",
    "\n",
    "    if not epochs_to_plot:\n",
    "        print(\"\\n⚠️ Não há dados suficientes para gerar os gráficos.\")\n",
    "    else:\n",
    "        # --- GRÁFICO: Loss por Época (Treino vs Validação) ---\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "        # Subplot 1: Train Loss\n",
    "        ax1.plot(epochs_to_plot, train_losses_plot,\n",
    "                 marker='x', linestyle='--', linewidth=2, markersize=6,\n",
    "                 color='blue', label='Train Loss')\n",
    "        ax1.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax1.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax1.set_title(\"Perda de Treino por Época\", fontsize=14, fontweight='bold')\n",
    "        ax1.legend(fontsize=11)\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "\n",
    "        # Subplot 2: Validation Loss\n",
    "        ax2.plot(epochs_to_plot, val_losses_plot,\n",
    "                 marker='o', linestyle='-', linewidth=2, markersize=6,\n",
    "                 color='red', label='Validation Loss')\n",
    "        ax2.set_xlabel(\"Época\", fontsize=12)\n",
    "        ax2.set_ylabel(\"Loss\", fontsize=12)\n",
    "        ax2.set_title(\"Perda de Validação por Época\", fontsize=14, fontweight='bold')\n",
    "        ax2.legend(fontsize=11)\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"✅ TREINAMENTO CONCLUÍDO COM SUCESSO!\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "except Exception as e:\n",
    "    import traceback\n",
    "    print(f\"\\n❌ Erro durante o treinamento ou avaliação:\")\n",
    "    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFSsNAWvaQQs"
   },
   "source": [
    "# **6. AVALIAÇÃO FINAL NO TESTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "0a5gLzc6aQuU",
    "outputId": "3adf7b91-9670-4bfa-b56a-d7959d01d0c2"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n==================== RESULTADOS FINAIS DO MODELO ====================\")\n",
    "print(\"\\nAvaliação no conjunto de teste:\")\n",
    "\n",
    "test_results = trainer.predict(test_dataset)\n",
    "final_metrics = test_results.metrics\n",
    "\n",
    "for metric, value in final_metrics.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SLL_XiZaSle"
   },
   "source": [
    "# **7. SALVAR MODELO E DADOS DE RESULTADOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbEnj8O5aUmx",
    "outputId": "71f79f28-8b46-4fc9-e3a4-5b5afefe1c6f"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "tokenizer.save_pretrained(\"/content/drive/MyDrive/2025/tcc-final/resultados/modelo_bertimbau_final\")\n",
    "print(\"Modelo salvo no Google Drive!\")\n",
    "\n",
    "# Salvar resultados do treinamento e rótulos/previsões finais\n",
    "output_results_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/resultados_fine_tuning.xlsx\"\n",
    "\n",
    "# Get the predictions from the test_results object\n",
    "predictions = np.argmax(test_results.predictions, axis=1)\n",
    "\n",
    "\n",
    "# Criar um DataFrame para os resultados de teste\n",
    "results_df = pd.DataFrame({\n",
    "    'texto': test_df['texto'],\n",
    "    'rotulo_verdadeiro': test_df['classe'],\n",
    "    'rotulo_predito_id': predictions,\n",
    "    'rotulo_predito': [id2label[p] for p in predictions]\n",
    "})\n",
    "\n",
    "# Salvar o DataFrame de resultados em um arquivo Excel\n",
    "results_df.to_excel(output_results_path, index=False)\n",
    "print(f\"Resultados de teste (texto, rótulo verdadeiro, rótulo predito) salvos em: {output_results_path}\")\n",
    "\n",
    "# Salvar as métricas finais em um arquivo de texto ou CSV\n",
    "metrics_output_path = \"/content/drive/MyDrive/2025/tcc-final/resultados/metricas_finais.txt\"\n",
    "with open(metrics_output_path, 'w') as f:\n",
    "    f.write(\"Métricas Finais da Avaliação no Conjunto de Teste:\\n\")\n",
    "    for metric_name, value in final_metrics.items():\n",
    "        f.write(f\"{metric_name}: {value:.4f}\\n\")\n",
    "print(f\"Métricas finais salvas em: {metrics_output_path}\")\n",
    "\n",
    "# --- FIM DO CONTADOR DE TEMPO ---\n",
    "end_total_time = time.time()\n",
    "total_execution_time = end_total_time - start_total_time\n",
    "print(f\"\\nTempo total de execução do script: {total_execution_time:.2f} segundos\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
