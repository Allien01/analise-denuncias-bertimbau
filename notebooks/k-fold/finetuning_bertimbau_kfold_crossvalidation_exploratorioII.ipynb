{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsCCzLwYbKDF"
   },
   "source": [
    "@inproceedings{souza2020bertimbau, author = {F{'a}bio Souza and Rodrigo Nogueira and Roberto Lotufo}, title = {{BERT}imbau: pretrained {BERT} models for {B}razilian {P}ortuguese}, booktitle = {9th Brazilian Conference on Intelligent Systems, {BRACIS}, Rio Grande do Sul, Brazil, October 20-23 (to appear)}, year = {2020} }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VU_ldpdMEMbw",
    "outputId": "4a713942-1422-4f2e-bb98-070855d8525c"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BkkHsJY5z-5",
    "outputId": "a8d201fc-342b-4ed1-ed66-407cd13fca2c"
   },
   "outputs": [],
   "source": [
    "!pip install nbstripout\n",
    "!nbstripout /content/drive/MyDrive/2025/tcc-final/fine_tuning_Bertimbau_version2_24_07.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "feHRGfqdONsa",
    "outputId": "d7fd4de0-1595-493e-d05c-afe9dc462d79"
   },
   "outputs": [],
   "source": [
    "!pip install transformers evaluate accelerate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback # Importa explicitamente para o callback\n",
    ")\n",
    "import torch\n",
    "from torch.utils.data import Dataset as TorchDataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import subprocess\n",
    "import time\n",
    "import evaluate\n",
    "start_total_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkRUcLU1PHke"
   },
   "source": [
    "# **1. Preparação do Dataset para K-Fold**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gG-9Pr_Mw3jU"
   },
   "source": [
    "Iniciamos carregando o dataset completo de denúncias. Diferente do método anterior, aqui não faremos uma divisão fixa. Em vez disso, usaremos a ***técnica de Validação Cruzada (K-Fold)***, que nos permite treinar e validar o modelo várias vezes em subconjuntos diferentes do nosso dataset, obtendo uma avaliação de desempenho mais confiável e robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3O3x60E3PHtT",
    "outputId": "26cec6ec-37da-4a45-e5e1-40168f9965d6"
   },
   "outputs": [],
   "source": [
    "# Carregar dataset já processado\n",
    "file_path = '/content/drive/MyDrive/2025/tcc-final/denuncias_balanceadas.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "print(f\"Dataset carregado. Total de registros: {len(df)}\")\n",
    "print(\"Primeiras 5 linhas do dataset:\")\n",
    "print(df.head())\n",
    "print(\"\\nInformações do dataset:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIeftoByY356"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE3WAEgOPYHa"
   },
   "source": [
    "# **2. Processando o Texto com o BERTimbau**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoC0YTBEYuA6"
   },
   "source": [
    "Assim como na abordagem anterior, esta etapa é crucial para preparar o texto. Usamos o ***tokenizer*** do modelo ***BERTimbau*** para converter as denúncias em um formato numérico compreensível pelo modelo. Também criamos classes personalizadas ***(CustomDataset)*** e um *** DataCollator*** para otimizar a forma como os dados são alimentados ao modelo durante o treinamento e a avaliação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275,
     "referenced_widgets": [
      "bbf66ecc69424fdfa40d0ff1ea5e59b6",
      "4f89c73964d24772ac7eb7c1439adc4e",
      "111ecf48650a4dc09138026d05774912",
      "de6ef983f2c646fab9ff44b7c273abcc",
      "1fca8535d59c4cb38f9a63d47b3f6ada",
      "e84c596b8e0f4e4486a6db430620a153",
      "53edbe9392bf4fe6a9d66b1adf86af3e",
      "00a135fc459e4738a28f6785664455bf",
      "fdaffd9767f04459a6374eedb4930221",
      "8429605866c248f5b4ffdf7879cf610c",
      "9d3e7767d4dc49f1a901190853e3774b",
      "207b685b31254130ac6be4815fbc881a",
      "d358842185794dbb805c80ec6614204f",
      "457734a2e9084c2388a324d3703a6779",
      "c20033cc3dbc4c9b911e8a2557ba60f1",
      "535e6baf2d9c4cd8b2f82a7de73eacb3",
      "8104c30704e14610b772e07c53683e49",
      "c701b1e763d64203969aadb3bd29cf1a",
      "da6e4139b51d48ff8f4c89f288fb3a67",
      "ef68d8be0492407592a1be07c6927467",
      "7642326dc2164187bd3f20ef94f0d272",
      "af413a53e5034547a6b5e364d217434c",
      "80164126a5e9483594a4bfb6409ffe3e",
      "7a1e8b4c07c74fbe98e20ac94c1bdcd4",
      "7e14f2a101324d4fb0eb978b5bf313a3",
      "dcd877defe0842919ed9d13f9dfc8f9f",
      "92352331d63342e8b83e539eecc8f247",
      "0ceaff91dc084633941a9a52cb099027",
      "f0b168ae8a6f418f8bf7b6759bf04317",
      "46c0afd663234dd2beb7e70781dee23d",
      "c72ff8c2323647feabfde6df0ff68ab6",
      "faf3757332444fe4bbdcb66e2f87fae2",
      "423db8295baf48cfb84e4307cb8f4229",
      "3b3205b6acd14108b903dbfe4ebd466c",
      "777238179e2c4d4790323f8fc9c7ec1b",
      "99657e972dec40278f39a7257bc93673",
      "7e4071e40ba04f51a3d3f4772832885d",
      "55b02aa938934a468f8fdd966e64951e",
      "64c8111d32944e959b4330f40385b61c",
      "12ca66c523fe4a1f93dadd13e82cf30e",
      "e3b877f51cf045d4b71c64b451041e42",
      "8193469c2dbf44ad9a3014a62a08feab",
      "6419024363964678b176de1fe412f16a",
      "b6d4d30e4ff84068953bdc7edeb210d4",
      "844b7c6397af4d1189e858eea7be079d",
      "013672db1f254f2eadf5d460f4873865",
      "9427535640394451a5e0af39d02361bd",
      "8957c7017f4c4d44a19ef2b9177fcf70",
      "e9aa4bb882594b7faf242aefeca72fe3",
      "988841234fb14f189d40b47abd145ac5",
      "7007526fbbcf4cfbaf3da2810713bcd2",
      "01474d1df1dc40e5a47a58c030feeec6",
      "e83a79c03f32437e95ed9f162feffd13",
      "8343af730ef14eac92b4c56e856c50b6",
      "7697870a4e1b4d15a77fb32ca94efa60"
     ]
    },
    "id": "sql7RSXMPd1g",
    "outputId": "db99bfd8-c3f2-443c-f8a3-f03914ebcf07"
   },
   "outputs": [],
   "source": [
    "model_path = \"neuralmind/bert-base-portuguese-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(batch[\"texto\"], truncation=True, max_length=512, padding='longest', return_tensors='pt')\n",
    "\n",
    "# Mapeamento de Labels: Essencial para o modelo e métricas\n",
    "id2label = {0: \"invasao_domicilio\", 1: \"violencia_fisica\"}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# Custom Dataset (para trabalhar com tensores PyTorch diretamente)\n",
    "class CustomDataset(TorchDataset): # Certifique-se que 'Dataset' foi importado corretamente\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings # Agora será um dicionário de tensores (input_ids, attention_mask)\n",
    "        self.labels = labels       # Agora será uma lista de labels (ou Series com índice reiniciado)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long) # Acesso direto pelo índice\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# Data Collator para padding dinâmico durante o treinamento\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2S-nz2HQZ0CA"
   },
   "source": [
    "# **3. Métricas de Desempenho**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eIMdebFsx3td"
   },
   "source": [
    "Para avaliar o desempenho do nosso modelo de forma completa, definimos uma série de métricas. Além da ***acurácia*** (a proporção de acertos), calculamos o ***AUC-ROC*** (que mede a capacidade de distinção entre as classes), e as métricas de ***Precisão, Recall e F1-Score***. O cálculo dessas métricas para cada classe e a média (***macro***) nos dão uma visão detalhada do desempenho do modelo, especialmente em datasets com classes desbalanceadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176,
     "referenced_widgets": [
      "c75ab0e668dd4e2ca95d65bf1c78c992",
      "5e6ac788fb044287be6e956e0d55c2ea",
      "0ac4458cf3634b8787eb63282e5d2bdc",
      "db1ed97cb69744af8e052d4fd575c885",
      "f265bba5c8fe464b96806f2d4b597113",
      "3b70c000ce9f4ec080eeade7a56202e0",
      "8be745a79e6049e2ae4c2c910ae03399",
      "dcac2ca0ce1a4c4a88b2afed520737ad",
      "0bb96c63e19d40e194b4b0c3e3c81244",
      "73c154ca61424943a127cf649955a2f9",
      "7d530f57095142a29f2ad8dea52bedeb",
      "f6013d9b1f17487db3e47e7cde824051",
      "6ccffc23449d4f2c923664f537774acd",
      "104d1485df954e88a051d80da4ce711e",
      "1fff2e75f94948a9b9217c584bc70729",
      "65c2428369664a4896dc889a62f907d4",
      "08bc09accc2947f19de1c75e3d6e35ac",
      "9c2be6f5e502432ab9b2d6170f4a6d71",
      "96b020ef1e934b6b86e4270184c5b980",
      "0d1559fbfb8f451b877e4de2d0a614c2",
      "4a2ba185fc4b48619a4e4c8607f7e233",
      "2b18899fffdc4cc6801709db05f00654",
      "327c65cb7638429ab3306bc7a4916ef9",
      "dd19444b5c004d269211382e89f004af",
      "1d127579e52040b4ad60657d40f1cd64",
      "23a346ebf5d444a9a46c8c30c7b4277e",
      "a369ab8462c54739a9abfa635fc7ca76",
      "3edbd1bbac894a629d8f0d580a1d5b23",
      "9a3c9c43c2be4314952da1f708674f8a",
      "d39789cc6f7f4606825ca053f61c06f5",
      "c5c1e397624f4c2897c8a30871648eb9",
      "a24a1a2c5c5a4e5e882999f9d08c29f3",
      "35d1aacf34ab4d01b7f8c56e8d38a7e3",
      "8aa0fb83107d4fbab07581269ced720d",
      "ef1f5da36d8a46fdaaa521466e1a17da",
      "fa0a4b9dcfd84e56b3d5d841f8926a52",
      "d7b315ac150f4ae59bd8462f81d0c8d9",
      "0a6f6468c8024518b875b6df4ccc2924",
      "cb9bb1d7bee94b639c8f39e7d654d0f9",
      "72d787e569be45dea539ce1eecb99e18",
      "35216661b09d4d47b2e533e5b7b735a2",
      "8c2250faf22d499483d40c0f079fec51",
      "1022110008e44ca4a2cd15188647726c",
      "0955f68e563d4e8abb896ffcc6f926d6",
      "157f5f5e23914374bcab16cad690baa5",
      "8a14d9980a33473c9ce07cce9bba4389",
      "b93df804766446dd8d110f45573399c2",
      "0a1c83cbc8e048e2a488243e551af9cc",
      "93acdce24af94bf0a9a674b4633d9e7a",
      "653a1ea8a1804e1ab3dbcae7da6c9b90",
      "204e1b329d74434c8df3616578fba65f",
      "ca197816677445e4a00fb8df6b688487",
      "e02da498df234672b223cd02fb0cdd3e",
      "5a32d691fe8e4f5fb624c8c59053498c",
      "da7671a846c645a2bf15111e6650b8ff"
     ]
    },
    "id": "F-gctrIbZ1Pv",
    "outputId": "948f03a1-4aa2-4180-877a-fd97110a9ed8"
   },
   "outputs": [],
   "source": [
    "precision_metric = evaluate.load(\"precision\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "auc_metric = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    try:\n",
    "        predictions, labels = eval_pred\n",
    "        probabilities = np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)) / np.sum(np.exp(predictions - np.max(predictions, axis=-1, keepdims=True)), axis=-1, keepdims=True)\n",
    "        positive_class_probs = probabilities[:, 1]\n",
    "\n",
    "        # Classe prevista (ID da maior probabilidade)\n",
    "        preds = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Labels das classes, conforme definido no notebook\n",
    "        class_labels = [label2id[\"invasao_domicilio\"], label2id[\"violencia_fisica\"]]\n",
    "\n",
    "        # --- CÁLCULO DAS MÉTRICAS ---\n",
    "        acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "        auc = auc_metric.compute(prediction_scores=positive_class_probs, references=labels)[\"roc_auc\"]\n",
    "\n",
    "        f1_results_by_class = f1_metric.compute(predictions=preds, references=labels, average=None, labels=class_labels)[\"f1\"]\n",
    "        f1_macro = f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"]\n",
    "\n",
    "        precision_results_by_class = precision_metric.compute(predictions=preds, references=labels, average=None, labels=class_labels)[\"precision\"]\n",
    "        precision_macro = precision_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"precision\"]\n",
    "\n",
    "        recall_results_by_class = recall_metric.compute(predictions=preds, references=labels, average=None, labels=class_labels)[\"recall\"]\n",
    "        recall_macro = recall_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"recall\"]\n",
    "\n",
    "        # --- RETORNO DO DICIONÁRIO COMPLETO DE MÉTRICAS ---\n",
    "        return {\n",
    "            \"accuracy\": round(acc, 4),\n",
    "            \"auc\": round(auc, 4),\n",
    "            \"f1_invasao\": round(f1_results_by_class[0], 4),\n",
    "            \"f1_violencia\": round(f1_results_by_class[1], 4),\n",
    "            \"precision_invasao\": round(precision_results_by_class[0], 4),\n",
    "            \"precision_violencia\": round(precision_results_by_class[1], 4),\n",
    "            \"recall_invasao\": round(recall_results_by_class[0], 4),\n",
    "            \"recall_violencia\": round(recall_results_by_class[1], 4),\n",
    "            \"precision_macro\": round(precision_macro, 4),\n",
    "            \"recall_macro\": round(recall_macro, 4),\n",
    "            \"f1_macro\": round(f1_macro, 4)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Erro no cálculo de métricas: {str(e)}\")\n",
    "        # Em caso de erro, retorna valores padrão para não quebrar o treinamento\n",
    "        return {\n",
    "            \"accuracy\": 0.0,\n",
    "            \"auc\": 0.0,\n",
    "            \"f1_invasao\": 0.0,\n",
    "            \"f1_violencia\": 0.0,\n",
    "            \"precision_invasao\": 0.0,\n",
    "            \"precision_violencia\": 0.0,\n",
    "            \"recall_invasao\": 0.0,\n",
    "            \"recall_violencia\": 0.0,\n",
    "            \"precision_macro\": 0.0,\n",
    "            \"recall_macro\": 0.0,\n",
    "            \"f1_macro\": 0.0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fmwNJA-Z5DK"
   },
   "source": [
    "# **4. Validação Cruzada (K-Fold) com Early Stopping**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hwxxmwBqyXXV"
   },
   "source": [
    "Esta é a etapa central do nosso projeto. Utilizamos a ***Validação Cruzada com 5 folds*** para treinar o modelo. Isso significa que o dataset é dividido em 5 partes: o modelo é treinado em 4 delas e validado na 5ª. Este processo se repete 5 vezes, garantindo que todas as denúncias sejam usadas na validação e nos dando uma estimativa mais precisa do desempenho geral do modelo. O ***Early Stopping*** é uma ferramenta crucial para evitar o overfitting, interrompendo o treinamento se o modelo parar de melhorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "36844df92b5f4866b6cb465e728bd843",
      "f5bc11d62c9b477d84f6ffcd576f63da",
      "50d38d2697f64ce9a34ad89261103b78",
      "14970fcfec0f4487b1fcaf09acbfdaab",
      "ec6d0deecf7f4dc68ee5dee7bc63ea36",
      "83da3487288f46fabe6ca930e96a861d",
      "e9c4f2e86de04b0caa6bcf29420871f7",
      "a84e77706d944841b2d14363f79ad9ea",
      "e866008dcb8142ebb93097043c6725c7",
      "a5606a07456047d1b7d0cfb5b472afe1",
      "f5afe028e1aa4dee8e55283456bfd3b4",
      "3f4a348e56d54a45ba741f811ffdaf49",
      "f4ea5ca17e57472f8db28261b8f67e45",
      "62817f0ed07d4f12a7abe8e3014e351f",
      "024fa766961649349106ac7b5035a3e9",
      "daa2263406924102a994c2c16621d6ea",
      "761924d544ef437dad28c4dbb4bc6b95",
      "d5a56ae0775a453c95ea7695a95faa9e",
      "aeb1fdddd9dd46e2aefa88fe04988134",
      "f2c28c7fd5e94aa98ec12ba0bbd3be14",
      "96c4809483994e7887c46d356658acff",
      "436b094a99494f81bb88f19f2cf26f0b"
     ]
    },
    "id": "Vf6OgrwXH9QE",
    "outputId": "cdc32c54-a3fe-4d8b-b897-6345bf028a72"
   },
   "outputs": [],
   "source": [
    "# Essas listas armazenarão o histórico de métricas de CADA fold para a plotagem.\n",
    "all_fold_train_losses = []\n",
    "all_fold_eval_losses = []\n",
    "all_fold_eval_accuracies = []\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Parâmetros de Treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bertimbau-denuncias-cv\", # Diretório de saída para K-Fold\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=30, # Aumentado para permitir que Early Stopping atue\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\", # Monitorar a perda de validação\n",
    "    greater_is_better=False, # Menor perda é melhor\n",
    "    logging_dir=\"./logs-cv\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    disable_tqdm=False,\n",
    "    report_to=\"none\",\n",
    "    fp16=True, # Treinamento com precisão mista\n",
    "    seed=42, # Semente para reprodutibilidade\n",
    "    gradient_accumulation_steps=1,\n",
    "    remove_unused_columns=True,\n",
    "    label_names=[\"labels\"]\n",
    ")\n",
    "\n",
    "# Preparar dados para K-Fold\n",
    "all_texts = df['texto'].tolist()\n",
    "all_labels_mapped = df['classe'].map(label2id).tolist() # Labels já mapeadas para IDs numéricos\n",
    "\n",
    "N_SPLITS = 5\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista para armazenar as métricas de teste de cada fold\n",
    "all_fold_test_metrics = []\n",
    "print(f\"\\n🚀 Iniciando Treinamento com K-Fold Cross-Validation ({N_SPLITS} folds)....\\n\")\n",
    "\n",
    "# Loop através dos folds\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(all_texts, all_labels_mapped)):\n",
    "    print(f\"\\n==================== INICIANDO FOLD {fold+1}/{N_SPLITS} ====================\")\n",
    "\n",
    "    # Dividir os dados para o fold atual\n",
    "    train_fold_texts = [all_texts[i] for i in train_index]\n",
    "    train_fold_labels = [all_labels_mapped[i] for i in train_index]\n",
    "    test_fold_texts = [all_texts[i] for i in test_index]\n",
    "    test_fold_labels = [all_labels_mapped[i] for i in test_index]\n",
    "\n",
    "    # Tokenizar os dados para o fold atual\n",
    "    train_fold_encodings = tokenize_function({\"texto\": train_fold_texts})\n",
    "    test_fold_encodings = tokenize_function({\"texto\": test_fold_texts})\n",
    "\n",
    "    # Criar CustomDatasets para o fold atual\n",
    "    train_dataset = CustomDataset(train_fold_encodings, train_fold_labels)\n",
    "    eval_dataset_for_trainer = CustomDataset(test_fold_encodings, test_fold_labels)\n",
    "\n",
    "    # Re-instanciar o modelo para cada fold\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels=2,\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "\n",
    "    # Congelar camadas do BERT (exceto pooler e classificador)\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'classifier' not in name and 'pooler' not in name:\n",
    "            param.requires_grad = False\n",
    "\n",
    "    print(f\"⚙️ Número de parâmetros treináveis no FOLD {fold+1}: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "\n",
    "    # Re-instanciar o Trainer para cada fold\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset_for_trainer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=1e-3)],\n",
    "        compute_metrics=compute_metrics,\n",
    "        data_collator=data_collator\n",
    "    )\n",
    "\n",
    "    # Treinar o modelo para o fold atual\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "\n",
    "        # Salvar o best model do fold atual\n",
    "        output_dir_fold = f\"/content/drive/MyDrive/2025/tcc-final/resultados_kfold/fold-{fold+1}\"\n",
    "        trainer.save_model(output_dir_fold)\n",
    "        print(f\"✅ Modelo salvo em: {output_dir_fold}\")\n",
    "\n",
    "        # Perform evaluation on the test set\n",
    "        evaluation_output = trainer.evaluate(eval_dataset_for_trainer)\n",
    "\n",
    "        # Extract predictions and true labels\n",
    "        predictions = trainer.predict(eval_dataset_for_trainer).predictions\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "        true_labels = eval_dataset_for_trainer.labels\n",
    "\n",
    "        # Map predicted labels back to original class names\n",
    "        predicted_class_names = [id2label[label] for label in predicted_labels]\n",
    "        true_class_names = [id2label[label] for label in true_labels]\n",
    "\n",
    "        # Create a DataFrame with predictions\n",
    "        predictions_df = pd.DataFrame({\n",
    "            \"texto\": test_fold_texts,\n",
    "            \"classe_verdadeira\": true_class_names,\n",
    "            \"classe_prevista\": predicted_class_names\n",
    "        })\n",
    "\n",
    "        # Save predictions to Excel\n",
    "        predictions_output_path = f\"/content/drive/MyDrive/2025/tcc-final/resultados_kfold/fold_{fold+1}_predictions.xlsx\"\n",
    "        predictions_df.to_excel(predictions_output_path, index=False)\n",
    "        print(f\"✅ Previsões salvas em: {predictions_output_path}\")\n",
    "\n",
    "        # --- LÓGICA SIMPLIFICADA DE COLETA DE MÉTRICAS ---\n",
    "        logs = trainer.state.log_history\n",
    "\n",
    "        # Listas temporárias para as métricas deste fold\n",
    "        fold_train_losses = []\n",
    "        fold_eval_losses = []\n",
    "        fold_eval_accuracies = []\n",
    "\n",
    "        # Agora é simples: 1 log por época para cada métrica\n",
    "        for log_entry in logs:\n",
    "            if 'loss' in log_entry and 'eval_loss' not in log_entry:\n",
    "                fold_train_losses.append(log_entry['loss'])\n",
    "            if 'eval_loss' in log_entry:\n",
    "                fold_eval_losses.append(log_entry['eval_loss'])\n",
    "                fold_eval_accuracies.append(log_entry['eval_accuracy'])\n",
    "\n",
    "        # 🔍 DIAGNÓSTICO: Verificar se está tudo alinhado\n",
    "        print(f\"\\n📊 FOLD {fold+1} - Métricas coletadas:\")\n",
    "        print(f\"   • Train losses: {len(fold_train_losses)} épocas\")\n",
    "        print(f\"   • Eval losses: {len(fold_eval_losses)} épocas\")\n",
    "        print(f\"   • Eval accuracies: {len(fold_eval_accuracies)} épocas\")\n",
    "\n",
    "        # ⚠️ SEGURANÇA: Garantir mesmo tamanho (caso haja alguma inconsistência)\n",
    "        min_length = min(len(fold_train_losses), len(fold_eval_losses))\n",
    "        if len(fold_train_losses) != len(fold_eval_losses):\n",
    "            print(f\"   ⚠️ AVISO: Tamanhos diferentes! Ajustando para {min_length} épocas\")\n",
    "            fold_train_losses = fold_train_losses[:min_length]\n",
    "            fold_eval_losses = fold_eval_losses[:min_length]\n",
    "            fold_eval_accuracies = fold_eval_accuracies[:min_length]\n",
    "\n",
    "        # Armazenar as curvas de métricas deste fold\n",
    "        all_fold_train_losses.append(fold_train_losses)\n",
    "        all_fold_eval_losses.append(fold_eval_losses)\n",
    "        all_fold_eval_accuracies.append(fold_eval_accuracies)\n",
    "        # --------------------------------------------------------\n",
    "\n",
    "        print(f\"\\n📊 Métricas finais de treino para FOLD {fold+1}:\")\n",
    "        print(f\"   Loss: {train_result.metrics.get('train_loss', 'N/A'):.4f}\")\n",
    "        print(f\"   Tempo total: {train_result.metrics.get('train_runtime', 'N/A'):.2f}s\")\n",
    "\n",
    "        # Evaluate on test set\n",
    "        print(f\"🧪 Avaliação no conjunto de teste/validação do FOLD {fold+1}...\")\n",
    "        fold_test_metrics = trainer.evaluate(eval_dataset_for_trainer)\n",
    "        all_fold_test_metrics.append(fold_test_metrics)\n",
    "        print(f\"   Resultados do FOLD {fold+1}: {fold_test_metrics}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"❌ Erro durante o treinamento do FOLD {fold+1}:\")\n",
    "        print(traceback.format_exc())\n",
    "        all_fold_test_metrics.append({\n",
    "            'eval_loss': float('nan'),\n",
    "            'eval_accuracy': 0.0,\n",
    "            'eval_auc': 0.0,\n",
    "            'eval_f1_invasao': 0.0,\n",
    "            'eval_f1_violencia': 0.0,\n",
    "            'eval_runtime': float('nan'),\n",
    "            'eval_samples_per_second': 0.0,\n",
    "            'eval_steps_per_second': 0.0\n",
    "        })\n",
    "\n",
    "# --- CÓDIGO DE PLOTAGEM SIMPLIFICADO ---\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# --- Gráfico 1: Perda de Treino por Época ---\n",
    "for i, train_loss_history in enumerate(all_fold_train_losses):\n",
    "    epochs = range(1, len(train_loss_history) + 1)\n",
    "    ax1.plot(epochs, train_loss_history,\n",
    "             marker='x', linestyle='--', label=f'Fold {i+1}')\n",
    "\n",
    "ax1.set_xlabel(\"Época\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Perda de Treino por Época (Todos os Folds)\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# --- Gráfico 2: Perda de Validação por Época ---\n",
    "for i, eval_loss_history in enumerate(all_fold_eval_losses):\n",
    "    epochs = range(1, len(eval_loss_history) + 1)\n",
    "    ax2.plot(epochs, eval_loss_history,\n",
    "             marker='o', linestyle='-', label=f'Fold {i+1}')\n",
    "\n",
    "ax2.set_xlabel(\"Época\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_title(\"Perda de Validação por Época (Todos os Folds)\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFSsNAWvaQQs"
   },
   "source": [
    "# **5. RESULTADOS FINAIS DA VALIDAÇÃO CRUZADA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a5gLzc6aQuU",
    "outputId": "17398c97-e187-4ef5-84cd-84302f32632f"
   },
   "outputs": [],
   "source": [
    "print(\"\\n\\n==================== RESULTADOS FINAIS K-FOLD CROSS-VALIDATION ====================\")\n",
    "\n",
    "if all_fold_test_metrics:\n",
    "    # Coletar todas as métricas de todos os folds\n",
    "    df_metrics = pd.DataFrame(all_fold_test_metrics)\n",
    "\n",
    "    # Calcular médias e desvios padrão\n",
    "    avg_metrics = df_metrics.mean(numeric_only=True).round(4).to_dict()\n",
    "    std_metrics = df_metrics.std(numeric_only=True).round(4).to_dict()\n",
    "\n",
    "    print(\"Métricas Médias (e Desvio Padrão) em todos os Folds:\")\n",
    "    for metric, avg_value in avg_metrics.items():\n",
    "        # Excluir métricas de tempo/desempenho por segundo da apresentação principal se desejar\n",
    "        if 'runtime' not in metric and 'samples_per_second' not in metric and 'steps_per_second' not in metric:\n",
    "            print(f\"{metric}: {avg_value} (± {std_metrics.get(metric, 0)})\")\n",
    "else:\n",
    "    print(\"Nenhum resultado de fold foi coletado. Ocorreram erros em todos os folds.\")\n",
    "\n",
    "print(\"\\n✅ K-Fold Cross-Validation Concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SLL_XiZaSle"
   },
   "source": [
    "# **6. SALVAR MODELO (Considerações Pós K-Fold)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbEnj8O5aUmx",
    "outputId": "1e4d4d79-49b8-4f4d-87ef-8c05d5eb6ca1"
   },
   "outputs": [],
   "source": [
    "criterio = \"eval_accuracy\"  # ou \"eval_auc\", \"eval_f1_invasao\", etc.\n",
    "best_fold_idx = int(np.argmax([m.get(criterio, float('-inf')) for m in all_fold_test_metrics]))\n",
    "print(f\"🏆 Melhor modelo: Fold {best_fold_idx+1} com {criterio} = {all_fold_test_metrics[best_fold_idx][criterio]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
